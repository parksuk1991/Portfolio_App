# -*- coding: utf-8 -*-
"""APP_repository.ipynb
"""


# Enhanced app.py with data gap filling functionality
import streamlit as st
import yfinance as yf
import numpy as np
import pandas as pd
from datetime import datetime
import datetime as dt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
from scipy.stats import pearsonr
import warnings
warnings.filterwarnings('ignore')


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Portfolio Backtesting App",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë²¤ì¹˜ë§ˆí¬ ì´ë¦„ ë§¤í•‘
BENCHMARK_NAMES = {
    'SPY': 'S&P 500 ì§€ìˆ˜',
    'QQQ': 'Nasdaq 100 ì§€ìˆ˜',
    'ACWI': 'MSCI ACWI ì§€ìˆ˜'
}

# ë²¤ì¹˜ë§ˆí¬ ì˜µì…˜ (í‘œì‹œìš©)
BENCHMARK_OPTIONS = {
    'S&P 500 ì§€ìˆ˜': 'SPY',
    'Nasdaq 100 ì§€ìˆ˜': 'QQQ',
    'MSCI ACWI ì§€ìˆ˜': 'ACWI'
}

# ìœ ì‚¬ ìì‚° ë§¤í•‘
SIMILAR_ASSETS_MAP = {
    # ì„¹í„° ETF ë§¤í•‘
    'XLC': ['XTL', 'IYZ', 'VNQ'],  # Communication Services -> Telecom/Tech/REITs
    'XLY': ['RTH', 'XRT', 'VCR'],  # Consumer Discretionary -> Retail
    'XLP': ['VDC', 'PBJ', 'SZK'],  # Consumer Staples
    'XLE': ['VDE', 'IYE', 'DIG'],  # Energy
    'XLF': ['VFH', 'IYF', 'KBE'],  # Financials
    'XLV': ['VHT', 'IYH', 'PJP'],  # Healthcare
    'XLI': ['VIS', 'IYJ', 'PPA'],  # Industrials
    'XLB': ['VAW', 'IYM', 'SLX'],  # Materials
    'XLK': ['VGT', 'IYW', 'QQQ'],  # Technology
    'XLU': ['VPU', 'IDU', 'PUI'],  # Utilities

    # ìŠ¤íƒ€ì¼ ETF ë§¤í•‘
    'SPYV': ['IVE', 'VTV', 'DVY'],  # S&P 500 Value
    'SPYG': ['IVW', 'VUG', 'MGK'],  # S&P 500 Growth
    'VYM': ['DVY', 'VTV', 'SCHD'],  # High Dividend Yield
    'RSP': ['EQL', 'EWRS', 'SPY'],  # Equal Weight S&P 500
    'USMV': ['SPLV', 'EFAV', 'SPY'],  # Low Volatility
    'SPMO': ['MTUM', 'PDP', 'QQQ'],  # Momentum

    # ë¦¬ì „ ETF ë§¤í•‘
    'IDEV': ['EFA', 'VEA', 'ACWX'],  # Developed Markets
    'IEMG': ['EEM', 'VWO', 'SCHE'],  # Emerging Markets
}

# ëŒ€ì²´ ìì‚° í’€
FALLBACK_ASSETS = {
    'large_cap_growth': ['QQQ', 'VUG', 'IVW'],
    'large_cap_value': ['VTV', 'IVE', 'DVY'],
    'small_cap': ['IWM', 'VB', 'IJR'],
    'international_dev': ['EFA', 'VEA', 'ACWX'],
    'international_em': ['EEM', 'VWO', 'DEM'],
    'sectors': ['XLK', 'XLF', 'XLV', 'XLE', 'XLI'],
    'broad_market': ['SPY', 'VTI', 'ITOT']
}

def get_asset_classification(ticker):
    """ìì‚° ë¶„ë¥˜ í•¨ìˆ˜"""
    growth_etfs = ['SPYG', 'VUG', 'IVW', 'MGK', 'QQQ', 'XLK']
    value_etfs = ['SPYV', 'VTV', 'IVE', 'DVY', 'VYM']
    international_etfs = ['IDEV', 'EFA', 'VEA', 'IEMG', 'EEM', 'VWO']
    sector_etfs = ['XLC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLK', 'XLU']

    if ticker in growth_etfs:
        return 'large_cap_growth'
    elif ticker in value_etfs:
        return 'large_cap_value'
    elif ticker in international_etfs:
        return 'international_dev' if ticker in ['IDEV', 'EFA', 'VEA'] else 'international_em'
    elif ticker in sector_etfs:
        return 'sectors'
    else:
        return 'broad_market'

# í™•ì¥ëœ ìì‚° í’€
EXTENDED_ASSET_POOL = {
    'large_cap_us': ['SPY', 'VOO', 'IVV', 'VTI', 'ITOT', 'SPTM', 'SPLG'],
    'large_cap_growth': ['QQQ', 'VUG', 'IVW', 'MGK', 'SPYG', 'VONG', 'IWF'],
    'large_cap_value': ['VTV', 'IVE', 'DVY', 'SPYV', 'VONV', 'IWD', 'VYM'],
    'mid_cap': ['MDY', 'IJH', 'VO', 'IVOO', 'SPMD', 'IWR', 'VMOT'],
    'small_cap': ['IWM', 'VB', 'IJR', 'VTWO', 'SPSM', 'VBR', 'IWN'],
    'international_dev': ['EFA', 'IEUR', 'IXUS', 'VEA', 'IEFA', 'ACWX', 'IDEV', 'VTEB', 'SCHF'],
    'international_em': ['EEM', 'VWO', 'IEMG', 'SCHE', 'DEM', 'SPEM', 'EEMV'],
    'technology': ['XLK', 'QQQ', 'VGT', 'IYW', 'FTEC', 'SOXX', 'IGV'],
    'communications': ['XLC', 'XTL', 'IYZ'],
    'healthcare': ['XLV', 'VHT', 'IYH', 'FHLC', 'PJP', 'IHI', 'BBH'],
    'financials': ['XLF', 'VFH', 'IYF', 'FNCL', 'KBE', 'IAT', 'PFI'],
    'energy': ['XLE', 'VDE', 'IYE', 'FENY', 'DIG', 'IEO', 'PXE'],
    'materials': ['XLB', 'VAW', 'IYM', 'FMAT', 'SLX', 'IYZ', 'DBB'],
    'industrials': ['XLI', 'VIS', 'IYJ', 'FIDU', 'PPA', 'ITA', 'PRN'],
    'utilities': ['XLU', 'VPU', 'IDU', 'FUTY', 'PUI', 'JXI', 'RYU'],
    'consumer_disc': ['XLY', 'VCR', 'IYC', 'FDIS', 'RTH', 'XRT', 'PEJ'],
    'consumer_staples': ['XLP', 'VDC', 'IYK', 'FSTA', 'PBJ', 'SZK', 'KXI'],
    'real_estate': ['VNQ', 'IYR', 'SCHH', 'FREL', 'RWR', 'USRT', 'ICF'],
    'bonds': ['AGG', 'BND', 'IEFA', 'SCHZ', 'IEF', 'TLT', 'SHY'],
    'commodities': ['DJP', 'DBC', 'PDBC', 'GSG', 'COMT', 'BCI', 'RJA'],
    'minvol': ['USMV', 'SPLV', 'EFAV', 'IDLV'],
    'momentum': ['SPMO', 'MTUM', 'IMTM', 'PDP']
    
}

# ì¹´í…Œê³ ë¦¬ë³„ ìš°ì„ ìˆœìœ„ ì„¤ì • (ê°™ì€ ì¹´í…Œê³ ë¦¬ ë‚´ì—ì„œë§Œ ëŒ€ì²´)
CATEGORY_PRIORITY = {
    'large_cap_us': ['VOO', 'IVV', 'VTI', 'SPY', 'ITOT', 'SPTM', 'SPLG'],
    'large_cap_growth': ['VUG', 'IVW', 'QQQ', 'MGK', 'SPYG', 'VONG', 'IWF'],
    'large_cap_value': ['VTV', 'IVE', 'DVY', 'SPYV', 'VONV', 'IWD', 'VYM'],
    'mid_cap': ['VO', 'IJH', 'MDY', 'IVOO', 'SPMD', 'IWR', 'VMOT'],
    'small_cap': ['VB', 'IJR', 'IWM', 'VTWO', 'SPSM', 'VBR', 'IWN'],
    'international_dev': ['EFA', 'IEUR', 'IXUS', 'VEA', 'IEFA', 'ACWX', 'IDEV', 'VTEB', 'SCHF'],
    'international_em': ['VWO', 'IEMG', 'EEM', 'SCHE', 'DEM', 'SPEM', 'EEMV'],
    'technology': ['VGT', 'XLK', 'IYW', 'QQQ', 'FTEC', 'SOXX', 'IGV'],
    'communications': ['XLC','XTL', 'IYZ'],
    'healthcare': ['VHT', 'XLV', 'IYH', 'FHLC', 'PJP', 'IHI', 'BBH'],
    'financials': ['VFH', 'XLF', 'IYF', 'FNCL', 'KBE', 'IAT', 'PFI'],
    'energy': ['VDE', 'XLE', 'IYE', 'FENY', 'DIG', 'IEO', 'PXE'],
    'materials': ['VAW', 'XLB', 'IYM', 'FMAT', 'SLX', 'IYZ', 'DBB'],
    'industrials': ['VIS', 'XLI', 'IYJ', 'FIDU', 'PPA', 'ITA', 'PRN'],
    'utilities': ['VPU', 'XLU', 'IDU', 'FUTY', 'PUI', 'JXI', 'RYU'],
    'consumer_disc': ['VCR', 'XLY', 'IYC', 'FDIS', 'RTH', 'XRT', 'PEJ'],
    'consumer_staples': ['VDC', 'XLP', 'IYK', 'FSTA', 'PBJ', 'SZK', 'KXI'],
    'real_estate': ['VNQ', 'IYR', 'SCHH', 'FREL', 'RWR', 'USRT', 'ICF'],
    'bonds': ['BND', 'AGG', 'SCHZ', 'IEF', 'TLT', 'SHY', 'IEFA'],
    'commodities': ['DBC', 'PDBC', 'DJP', 'GSG', 'COMT', 'BCI', 'RJA'],
    'minvol': ['USMV', 'SPLV', 'EFAV', 'IDLV'],
    'momentum': ['SPMO', 'MTUM', 'IMTM', 'PDP']
}

def get_enhanced_asset_classification(ticker):
    """í–¥ìƒëœ ìì‚° ë¶„ë¥˜ - ë” ì„¸ë¶„í™”ëœ ì¹´í…Œê³ ë¦¬"""
    
    for category, tickers in EXTENDED_ASSET_POOL.items():
        if ticker in tickers:
            return category
    
    return 'large_cap_us'  # ê¸°ë³¸ê°’

def find_best_substitute_enhanced(target_ticker, available_data, start_date, end_date, min_correlation=0.3):
    """í–¥ìƒëœ ëŒ€ì²´ ìì‚° ì„ íƒ - ë™ì¼ ì¹´í…Œê³ ë¦¬ ë‚´ì—ì„œë§Œ ì„ íƒ"""
    
    # 1ë‹¨ê³„: íƒ€ê²Ÿ í‹°ì»¤ì˜ ì¹´í…Œê³ ë¦¬ í™•ì¸
    asset_category = get_enhanced_asset_classification(target_ticker)
    
    # 2ë‹¨ê³„: ë™ì¼ ì¹´í…Œê³ ë¦¬ ë‚´ í›„ë³´ ìì‚°ë“¤ (ìš°ì„ ìˆœìœ„ ìˆœì„œ)
    category_candidates = CATEGORY_PRIORITY.get(asset_category, [])
    
    # íƒ€ê²Ÿ í‹°ì»¤ ì œì™¸
    candidates = [ticker for ticker in category_candidates if ticker != target_ticker]
    
    if not candidates:
        print(f"Warning: No substitute candidates found for {target_ticker} in category {asset_category}")
        return None, None
    
    # 3ë‹¨ê³„: ê° í›„ë³´ì˜ ë°ì´í„° í’ˆì§ˆ ë° ì í•©ì„± í‰ê°€
    best_candidates = []
    
    for candidate in candidates:
        try:
            # í›„ë³´ ë°ì´í„° ë¡œë“œ
            candidate_data = yf.download(candidate, start=start_date, end=end_date, progress=False)
            
            if candidate_data.empty:
                continue
                
            candidate_prices = candidate_data['Close'] if 'Close' in candidate_data.columns else candidate_data
            
            if len(candidate_prices) < 100:  # ìµœì†Œ ë°ì´í„° ê¸¸ì´ ìš”êµ¬ì‚¬í•­ ì™„í™”
                continue
            
            # ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
            data_completeness = candidate_prices.count() / len(candidate_prices)
            if data_completeness < 0.7:  # 70% ì´ìƒ ë°ì´í„° ì™„ì „ì„±
                continue
            
            correlation_scores = []
            
            if len(available_data.columns) > 0:
                # ê³µí†µ ê¸°ê°„ ì°¾ê¸°
                common_period = candidate_prices.index.intersection(available_data.index)
                
                if len(common_period) > 50:  # ìµœì†Œ ê²¹ì¹˜ëŠ” ê¸°ê°„ ì™„í™”
                    candidate_returns = candidate_prices.loc[common_period].pct_change().dropna()
                    
                    for existing_asset in available_data.columns:
                        existing_returns = available_data[existing_asset].loc[common_period].pct_change().dropna()
                        
                        # ê³µí†µ ì¸ë±ìŠ¤
                        common_idx = candidate_returns.index.intersection(existing_returns.index)
                        
                        if len(common_idx) > 30:  # ìµœì†Œ ê³µí†µ ë°ì´í„° ì™„í™”
                            try:
                                corr, p_value = pearsonr(
                                    candidate_returns.loc[common_idx].fillna(0),
                                    existing_returns.loc[common_idx].fillna(0)
                                )
                                
                                if not np.isnan(corr):
                                    correlation_scores.append(abs(corr))
                            except:
                                continue
            
            # í‰ê·  ìƒê´€ê´€ê³„ ê³„ì‚°
            avg_correlation = np.mean(correlation_scores) if correlation_scores else 0
            
            # ë°ì´í„° ê¸¸ì´ ì ìˆ˜
            length_score = min(len(candidate_prices) / 1000, 1.0)  # 4ë…„ ê¸°ì¤€ ì •ê·œí™”
            
            # ìš°ì„ ìˆœìœ„ ì ìˆ˜ (ë¦¬ìŠ¤íŠ¸ì—ì„œ ì•ì— ìˆì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            priority_score = (len(candidates) - candidates.index(candidate)) / len(candidates)
            
            # ë³µí•© ì ìˆ˜ ê³„ì‚° (ìš°ì„ ìˆœìœ„ë¥¼ ë” ì¤‘ìš”í•˜ê²Œ ë°˜ì˜)
            composite_score = (priority_score * 0.4) + (length_score * 0.3) + (data_completeness * 0.2) + (avg_correlation * 0.1)
            
            best_candidates.append({
                'ticker': candidate,
                'data': candidate_prices,
                'correlation': avg_correlation,
                'length_score': length_score,
                'completeness': data_completeness,
                'priority_score': priority_score,
                'composite_score': composite_score
            })
            
        except Exception as e:
            print(f"Error processing candidate {candidate}: {str(e)}")
            continue
    
    # 4ë‹¨ê³„: ìµœê³  ì ìˆ˜ ëŒ€ì²´ ìì‚° ì„ íƒ
    if best_candidates:
        # ë³µí•© ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        best_candidates.sort(key=lambda x: x['composite_score'], reverse=True)
        
        # ê°€ì¥ ì¢‹ì€ í›„ë³´ ì„ íƒ
        best_candidate = best_candidates[0]
        
        print(f"Substituting {target_ticker} ({asset_category}) with {best_candidate['ticker']}")
        print(f"  - Data completeness: {best_candidate['completeness']:.2%}")
        print(f"  - Data length: {len(best_candidate['data'])} days")
        print(f"  - Average correlation: {best_candidate['correlation']:.3f}")
        
        return best_candidate['ticker'], best_candidate['data']
    
    # 5ë‹¨ê³„: ëª¨ë“  í›„ë³´ê°€ ì‹¤íŒ¨í•œ ê²½ìš° - ì¹´í…Œê³ ë¦¬ ë‚´ ì²« ë²ˆì§¸ ëŒ€ì•ˆ ì„ íƒ
    for candidate in candidates:
        try:
            fallback_data = yf.download(candidate, start=start_date, end=end_date, progress=False)
            if not fallback_data.empty:
                fallback_prices = fallback_data['Close'] if 'Close' in fallback_data.columns else fallback_data
                if len(fallback_prices) > 50:  # ìµœì†Œ ê¸°ì¤€ ì™„í™”
                    print(f"Using fallback substitute {candidate} for {target_ticker} (category: {asset_category})")
                    return candidate, fallback_prices
        except:
            continue
    
    return None, None


def fill_missing_data(tickers, start_date, end_date, fill_gaps=True):
    """ë°ì´í„° ê³µë°± ì±„ìš°ê¸°"""

    st.info("ğŸ“Š ë°ì´í„° ë¡œë”© ë° ê³µë°± ë¶„ì„ ì¤‘...")

    # ì›ë³¸ ë°ì´í„° ë¡œë“œ ì‹œë„
    original_data = {}
    missing_tickers = []
    data_info = {}

    for ticker in tickers:
        try:
            data = yf.download(ticker, start=start_date, end=end_date)['Close']

            if isinstance(data, pd.Series):
                data = data.to_frame(name=ticker)

            # ë°ì´í„° í’ˆì§ˆ í™•ì¸
            data_start = data.first_valid_index()
            data_end = data.last_valid_index()
            data_length = len(data.dropna())

            # ëª©í‘œ ì‹œì‘ì¼ê³¼ ì‹¤ì œ ë°ì´í„° ì‹œì‘ì¼ ë¹„êµ
            target_start = pd.to_datetime(start_date)

            if data_start is None or data_length < 50:
                missing_tickers.append(ticker)
                st.warning(f"âŒ {ticker}: ë°ì´í„° ë¶€ì¡± (ê¸¸ì´: {data_length})")
            elif data_start > target_start + pd.DateOffset(years=1):
                missing_tickers.append(ticker)
                st.warning(f"âš ï¸ {ticker}: ì‹œì‘ì¼ ë¶€ì¡± (ëª©í‘œ: {target_start.strftime('%Y-%m')}, ì‹¤ì œ: {data_start.strftime('%Y-%m')})")
                data_info[ticker] = {
                    'original_data': data,
                    'start_gap': (data_start - target_start).days,
                    'needs_filling': True
                }
            else:
                original_data[ticker] = data
                data_info[ticker] = {
                    'original_data': data,
                    'start_gap': 0,
                    'needs_filling': False
                }

        except Exception as e:
            missing_tickers.append(ticker)
            st.error(f"âŒ {ticker}: ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ - {str(e)}")

    if not fill_gaps or len(missing_tickers) == 0:
        if len(original_data) > 0:
            combined_data = pd.concat(original_data.values(), axis=1)
            combined_data.columns = original_data.keys()
            return combined_data.resample('ME').last().dropna(), {}
        else:
            return None, {}

    # ëŒ€ì²´ ìì‚° ì°¾ê¸° + ë°ì´í„° ê²°í•©
    st.info("ğŸ”„ ëŒ€ì²´ ìì‚° ê²€ìƒ‰ ë° ë°ì´í„° ê²°í•© ì¤‘...")

    substitution_log = {}
    enhanced_data = original_data.copy()

    # ê¸°ì¡´ ë°ì´í„° DataFrameìœ¼ë¡œ ê²°í•©
    if len(enhanced_data) > 0:
        available_data = pd.concat(enhanced_data.values(), axis=1)
        available_data.columns = enhanced_data.keys()
    else:
        available_data = pd.DataFrame()


        substitute_ticker, substitute_data = find_best_substitute_enhanced(
            ticker, available_data, start_date, end_date
        )

        if substitute_ticker and substitute_data is not None:
            # ëŒ€ì²´ ë°ì´í„° ì²˜ë¦¬
            if isinstance(substitute_data, pd.Series):
                substitute_data = substitute_data.to_frame(name=substitute_ticker)

            # ì›ë³¸ í‹°ì»¤ ì´ë¦„ìœ¼ë¡œ ì»¬ëŸ¼ëª… ë³€ê²½
            substitute_df = substitute_data.copy()
            substitute_df.columns = [ticker]

            enhanced_data[ticker] = substitute_df
            substitution_log[ticker] = {
                'substitute': substitute_ticker,
                'original_start': data_info.get(ticker, {}).get('original_data', pd.DataFrame()).first_valid_index(),
                'substitute_start': substitute_data.first_valid_index(),
                'method': 'similar_asset'
            }

            # available_data ì—…ë°ì´íŠ¸
            if len(available_data) == 0:
                available_data = substitute_df
            else:
                available_data = pd.concat([available_data, substitute_df], axis=1)
        else:
            st.error(f"âŒ {ticker}: ì ì ˆí•œ ëŒ€ì²´ ìì‚°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ìµœì¢… ë°ì´í„° ê²°í•©
    if len(enhanced_data) > 0:
        final_data = pd.concat(enhanced_data.values(), axis=1)
        final_data.columns = enhanced_data.keys()

        # ì›”ë§ ë¦¬ìƒ˜í”Œë§
        monthly_data = final_data.resample('ME').last().dropna()

        st.success(f"ğŸ‰ ìµœì¢… ë°ì´í„°ì…‹ ì™„ì„±: {len(monthly_data.columns)}ê°œ ìì‚°, {len(monthly_data)}ê°œì›” ë°ì´í„°")

        return monthly_data, substitution_log
    else:
        st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, {}

# ìºì‹œëœ ë°ì´í„° ë¡œë”
@st.cache_data
def load_universe_data_enhanced(tickers, start_date, end_date, fill_gaps=True):
    """ìœ ë‹ˆë²„ìŠ¤ ë°ì´í„°"""
    return fill_missing_data(tickers, start_date, end_date, fill_gaps)
    
@st.cache_data
def load_benchmark_data(ticker, start_date, end_date):
    """ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°"""
    try:
        data = yf.download(ticker, start=start_date, end=end_date)['Close']

        if isinstance(data, pd.Series):
            data = data.to_frame(name=ticker)
        elif isinstance(data, pd.DataFrame) and len(data.columns) == 1:
            data.columns = [ticker]

        monthly_prices = data.resample('ME').last()
        monthly_prices = monthly_prices.dropna()

        if len(monthly_prices.columns) == 1:
            return monthly_prices.iloc[:, 0]
        else:
            return monthly_prices

    except Exception as e:
        st.error(f"ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def adjust_weights_to_bounds(weights, upper_bound, lower_bound, max_iterations=100):
    """ê°€ì¤‘ì¹˜ ì¡°ì • í•¨ìˆ˜"""
    adjusted_weights = weights.copy()

    for iteration in range(max_iterations):
        adjusted_weights = np.minimum(adjusted_weights, upper_bound)
        adjusted_weights = np.maximum(adjusted_weights, lower_bound)

        total_weight = adjusted_weights.sum()

        if abs(total_weight - 1.0) < 1e-6:
            break

        if total_weight > 1.0:
            excess = total_weight - 1.0
            adjustable_mask = adjusted_weights > lower_bound
            if adjustable_mask.sum() > 0:
                reduction = excess * (adjusted_weights / adjusted_weights[adjustable_mask].sum())
                reduction[~adjustable_mask] = 0
                adjusted_weights = adjusted_weights - reduction
                adjusted_weights = np.maximum(adjusted_weights, lower_bound)
        else:
            deficit = 1.0 - total_weight
            adjustable_mask = adjusted_weights < upper_bound
            if adjustable_mask.sum() > 0:
                addition = deficit * (adjusted_weights / adjusted_weights[adjustable_mask].sum())
                addition[~adjustable_mask] = 0
                adjusted_weights = adjusted_weights + addition
                adjusted_weights = np.minimum(adjusted_weights, upper_bound)

    adjusted_weights = adjusted_weights / adjusted_weights.sum()
    return adjusted_weights


def run_backtest(stock_returns, window, top_n_stocks, upper_bound, lower_bound):
    """ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰"""
    portfolio_returns = []
    portfolio_dates = []
    portfolio_composition = {}
    weights_composition = {}
    prev_weights = None

    progress_bar = st.progress(0)
    total_iterations = len(stock_returns) - window

    for i in range(window, len(stock_returns)):
        progress_bar.progress((i - window) / total_iterations)

        current_date = stock_returns.index[i]
        past_returns = stock_returns.iloc[i-window:i]
        momentum_score = (1 + past_returns).prod() - 1

        if i % 1 == 0:  # ë§¤ì›” ë¦¬ë°¸ëŸ°ì‹±
            current_top_stocks = momentum_score.nlargest(top_n_stocks).index.tolist()
            portfolio_composition[current_date] = current_top_stocks

            lookback_period = min(36, i)
            if lookback_period < 12:
                continue

            historical_returns = stock_returns.iloc[i-lookback_period:i][current_top_stocks]
            if len(historical_returns) < 12:
                continue

            cov_matrix = historical_returns.cov()
            sigma_squared = np.diag(cov_matrix.values)
            sigma_squared = np.maximum(sigma_squared, 1e-8)

            momentum_scores = momentum_score[current_top_stocks].values
            momentum_scores = np.maximum(momentum_scores, 0.01)

            inverse_volatility = 1 / np.sqrt(sigma_squared)
            base_weights = inverse_volatility / inverse_volatility.sum()

            adjusted_weights = base_weights * np.sqrt(momentum_scores)
            adjusted_weights = adjusted_weights / adjusted_weights.sum()

            final_weights = adjust_weights_to_bounds(adjusted_weights, upper_bound, lower_bound)

            weights_composition[current_date] = dict(zip(current_top_stocks, final_weights))
            prev_weights = weights_composition[current_date]

        if prev_weights is not None:
            current_stocks = list(prev_weights.keys())
            weights_array = np.array(list(prev_weights.values()))

            available_returns = stock_returns.loc[current_date, current_stocks]

            if not available_returns.isna().any():
                portfolio_return = np.sum(weights_array * available_returns.values)
                portfolio_returns.append(portfolio_return)
                portfolio_dates.append(current_date)
            else:
                portfolio_returns.append(0.0)
                portfolio_dates.append(current_date)

    progress_bar.empty()

    return pd.Series(portfolio_returns, index=portfolio_dates), weights_composition

def safe_convert_to_float(value):
    """ê°’ì„ ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜"""
    try:
        if hasattr(value, 'item'):
            return float(value.item())
        elif hasattr(value, '__array__') and value.ndim == 0:
            return float(value)
        else:
            return float(value)
    except (ValueError, TypeError, AttributeError):
        return 0.0


def calculate_performance_metrics(returns, benchmark_returns=None):
    """ì„±ê³¼ ì§€í‘œ ê³„ì‚° (ì¶”ì ì˜¤ì°¨ í¬í•¨)"""
    if len(returns) == 0:
        return {
            'total_return': 0.0,
            'annualized_return': 0.0,
            'volatility': 0.0,
            'sharpe_ratio': 0.0,
            'max_drawdown': 0.0,
            'tracking_error': 0.0
        }

    total_return = safe_convert_to_float((1 + returns).prod() - 1)
    annualized_return = safe_convert_to_float((1 + returns.mean())**12 - 1)
    volatility = safe_convert_to_float(returns.std() * np.sqrt(12))

    sharpe_ratio = annualized_return / volatility if volatility > 0 else 0.0

    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = (cumulative - running_max) / running_max
    max_drawdown = safe_convert_to_float(drawdown.min())

    # ì¶”ì ì˜¤ì°¨ ê³„ì‚°
    tracking_error = 0.0
    if benchmark_returns is not None and len(benchmark_returns) > 0:
        # ê³µí†µ ì¸ë±ìŠ¤ ì°¾ê¸°
        common_index = returns.index.intersection(benchmark_returns.index)
        if len(common_index) > 1:
            aligned_returns = returns.loc[common_index]
            aligned_benchmark = benchmark_returns.loc[common_index]
            
            # ì´ˆê³¼ìˆ˜ìµë¥ ì˜ í‘œì¤€í¸ì°¨ (ì—°í™˜ì‚°)
            excess_returns = aligned_returns - aligned_benchmark
            tracking_error = safe_convert_to_float(excess_returns.std() * np.sqrt(12))

    return {
        'total_return': total_return,
        'annualized_return': annualized_return,
        'volatility': volatility,
        'sharpe_ratio': sharpe_ratio,
        'max_drawdown': max_drawdown,
        'tracking_error': tracking_error
    }

def calculate_portfolio_turnover(weights_composition):
    """í¬íŠ¸í´ë¦¬ì˜¤ íšŒì „ìœ¨ ê³„ì‚°"""
    if len(weights_composition) < 2:
        return 0.0
    
    dates = sorted(weights_composition.keys())
    turnovers = []
    
    for i in range(1, len(dates)):
        current_date = dates[i]
        previous_date = dates[i-1]
        
        current_weights = weights_composition[current_date]
        previous_weights = weights_composition[previous_date]
        
        # ëª¨ë“  ìì‚° ë¦¬ìŠ¤íŠ¸
        all_assets = set(list(current_weights.keys()) + list(previous_weights.keys()))
        
        # ê°€ì¤‘ì¹˜ ë³€í™”ëŸ‰ ê³„ì‚°
        total_change = 0.0
        for asset in all_assets:
            current_weight = current_weights.get(asset, 0.0)
            previous_weight = previous_weights.get(asset, 0.0)
            total_change += abs(current_weight - previous_weight)
        
        # íšŒì „ìœ¨ì€ ë³€í™”ëŸ‰ì˜ ì ˆë°˜ (ë§¤ë„ì™€ ë§¤ìˆ˜ê°€ ê°™ì€ ì–‘ì´ë¯€ë¡œ)
        turnover = total_change / 2.0
        turnovers.append(turnover)
    
    # ì—°ê°„ íšŒì „ìœ¨ë¡œ í™˜ì‚° (ì›”ë³„ ë¦¬ë°¸ëŸ°ì‹±ì´ë¯€ë¡œ 12ë¥¼ ê³±í•¨)
    annual_turnover = np.mean(turnovers) * 12 if turnovers else 0.0
    return annual_turnover



def get_rebalancing_changes(current_weights, previous_weights):
    """ë¦¬ë°¸ëŸ°ì‹± ë³€í™” ê³„ì‚°"""
    all_stocks = set(list(current_weights.keys()) + (list(previous_weights.keys()) if previous_weights else []))

    changes = {}
    for stock in all_stocks:
        current_weight = current_weights.get(stock, 0)
        previous_weight = previous_weights.get(stock, 0) if previous_weights else 0

        change = current_weight - previous_weight
        if abs(change) > 0.001:
            changes[stock] = {
                'previous': previous_weight,
                'current': current_weight,
                'change': change,
                'action': 'INCREASE' if change > 0 else 'DECREASE' if change < 0 else 'HOLD'
            }

    return changes

# 4. ì—°ë„ë³„/ì›”ë³„ ì„±ê³¼ ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜
def create_performance_charts(portfolio_returns, benchmark_returns, benchmark_name):
    """ì—°ë„ë³„ ë° ì›”ë³„ ì„±ê³¼ ë¹„êµ ì°¨íŠ¸ ìƒì„±"""
    
    # ê³µí†µ ê¸°ê°„ ë°ì´í„°
    common_index = portfolio_returns.index.intersection(benchmark_returns.index)
    port_aligned = portfolio_returns.loc[common_index]
    bench_aligned = benchmark_returns.loc[common_index]
    
    # ì—°ë„ë³„ ì„±ê³¼
    yearly_port = port_aligned.groupby(port_aligned.index.year).apply(lambda x: (1 + x).prod() - 1)
    yearly_bench = bench_aligned.groupby(bench_aligned.index.year).apply(lambda x: (1 + x).prod() - 1)
    
    # ì›”ë³„ ì„±ê³¼ (ìµœê·¼ 24ê°œì›”)
    monthly_port = port_aligned.tail(24)
    monthly_bench = bench_aligned.tail(24)
    
    # ì—°ë„ë³„ ì„±ê³¼ ì°¨íŠ¸
    fig_yearly = go.Figure()
    
    years = yearly_port.index
    fig_yearly.add_trace(go.Bar(
        x=years,
        y=yearly_port * 100,
        name='í¬íŠ¸í´ë¦¬ì˜¤',
        marker_color='deeppink',
        opacity=0.7
    ))
    fig_yearly.add_trace(go.Bar(
        x=years,
        y=yearly_bench * 100,
        name=benchmark_name,
        marker_color='royalblue',
        opacity=0.7
    ))
    
    fig_yearly.update_layout(
        title="ì—°ë„ë³„",
        xaxis_title="ì—°ë„",
        yaxis_title="ìˆ˜ìµë¥  (%)",
        barmode='group',
        template="plotly_dark",
        height=400
    )
    
    # ì›”ë³„ ì„±ê³¼ ì°¨íŠ¸
    fig_monthly = go.Figure()
    
    months = [f"{d.year}-{d.month:02d}" for d in monthly_port.index]
    fig_monthly.add_trace(go.Bar(
        x=months,
        y=monthly_port * 100,
        name='í¬íŠ¸í´ë¦¬ì˜¤',
        marker_color='deeppink',
        opacity=0.7
    ))
    fig_monthly.add_trace(go.Bar(
        x=months,
        y=monthly_bench * 100,
        name=benchmark_name,
        marker_color='royalblue',
        opacity=0.7
    ))
    
    fig_monthly.update_layout(
        title=f"ì›”ë³„ (ìµœê·¼ {len(monthly_port)}ê°œì›”)",
        xaxis_title="ì›”",
        yaxis_title="ìˆ˜ìµë¥  (%)",
        barmode='group',
        template="plotly_dark",
        height=400,
        xaxis=dict(tickangle=45)
    )
    
    return fig_yearly, fig_monthly

# ë©”ì¸ ì•±
def main():
    st.title("ğŸ“ˆ Portfolio Backtesting App")
    st.markdown("##### ë§Œë“ ì´: ë°•ì„")

    st.markdown(
        '<div style="text-align: right; margin-bottom: 10px;">'
        'Data ì¶œì²˜: <a href="https://finance.yahoo.com/" target="_blank">Yahoo Finance</a>'
        '</div>',
        unsafe_allow_html=True
    )

    # ì•± ì„¤ëª… ì„¹ì…˜ì„ expanderë¡œ ê°ì‹¸ê¸°
    with st.expander("ğŸ“‹ ì•± ì†Œê°œ", expanded=False):
        # ì•± ì„¤ëª… ì„¹ì…˜ì„ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„í• 
        col1, col2 = st.columns([3, 1])  # 3:1 ë¹„ìœ¨ë¡œ ë¶„í• 
        
        with col1:
            st.markdown("""
            **ì´ ì•±ì€ ë°ì´í„° ê³µë°± ìë™ ë³´ì™„ ê¸°ëŠ¥ì„ ê°–ì¶˜ ëª¨ë©˜í…€ ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ë°±í…ŒìŠ¤íŒ… ë„êµ¬ì…ë‹ˆë‹¤.**
            #### ğŸ¯ ì£¼ìš” ê¸°ëŠ¥
            - **ìì‚° ì„ íƒ**: ì›í•˜ëŠ” ETF, ì£¼ì‹ ë“± ììœ ë¡œìš´ íˆ¬ì ìœ ë‹ˆë²„ìŠ¤ ì„¤ì •
            - **íŒŒë¼ë¯¸í„° ì¡°ì •**: ëª¨ë©˜í…€ ê¸°ê°„, ì„ íƒ ì¢…ëª© ìˆ˜, ìµœëŒ€/ìµœì†Œ ê°€ì¤‘ì¹˜ ë“± ì „ëµ íŒŒë¼ë¯¸í„° ì¡°ì •
            - **ê¸°ê°„ ì„¤ì •**: ë°±í…ŒìŠ¤íŒ… ë¶„ì„ ê¸°ê°„ì„ ììœ ë¡­ê²Œ ì„¤ì • ê°€ëŠ¥
            - **ëª¨ë©˜í…€ ì „ëµ**: ê³¼ê±° ìˆ˜ìµë¥ ì„ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ ì¢…ëª©ì„ ì„ ë³„í•˜ì—¬ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ êµ¬ì„±
            - **ë¦¬ìŠ¤í¬ ì¡°ì •**: ì—­ë³€ë™ì„± ê°€ì¤‘ì¹˜ì™€ ëª¨ë©˜í…€ ìŠ¤ì½”ì–´ë¥¼ ê²°í•©í•œ ìŠ¤ë§ˆíŠ¸ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”
            - **ì›”ë³„ ë¦¬ë°¸ëŸ°ì‹±**: ë§¤ì›” í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì¬ì¡°ì •í•˜ì—¬ ìµœì ì˜ ìì‚° êµ¬ì„± ìœ ì§€
            #### âœ”ï¸ ë¶„ì„ ê²°ê³¼ ì œê³µ
            - **ì„±ê³¼ ì§€í‘œ**: ìˆ˜ìµë¥ , ë³€ë™ì„±, ìƒ¤í”„ ë¹„ìœ¨, ìµœëŒ€ ë‚™í­ ë“± ì£¼ìš” íˆ¬ì ì§€í‘œ ë¶„ì„
            - **ë²¤ì¹˜ë§ˆí¬ ë¹„êµ**: S&P 500, Nasdaq 100, MSCI ACWI ì§€ìˆ˜ì™€ì˜ ì„±ê³¼ ë¹„êµ
            - **ì‹œê°í™”**: ëˆ„ì  ìˆ˜ìµë¥ , ë¦¬ìŠ¤í¬ ë¶„ì„, í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ë³€í™” ë“± ë‹¤ì–‘í•œ ì°¨íŠ¸ ì œê³µ
            #### ğŸ”§ ë°ì´í„° ê³µë°± ë³´ì™„ ë°©ì‹
            - **ìœ ì‚¬ ì¢…ëª© ë§¤í•‘**: ì„ íƒí•œ ì¢…ëª©ì˜ ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš°, ìœ ì‚¬í•œ íŠ¹ì„±ì„ ê°€ì§„ ëŒ€ì²´ ì¢…ëª©ìœ¼ë¡œ ìë™ ë³´ì™„
            - **ìƒê´€ê´€ê³„ ë¶„ì„**: ê¸°ì¡´ ì¢…ëª©ê³¼ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ ëŒ€ì²´ ì¢…ëª© ì„ íƒ
            - **ìì‚° ë¶„ë¥˜ë³„ ëŒ€ì²´**: ì„±ì¥ì£¼, ê°€ì¹˜ì£¼, ì„¹í„°ë³„ ë“± ìì‚° íŠ¹ì„±ì— ë”°ë¥¸ ì²´ê³„ì  ëŒ€ì²´
            """)
        
        with col2:
            st.markdown("""
            <div style="
                height: 600px;
                display: flex;
                align-items: center;
                justify-content: center;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                border-radius: 15px;
                margin-top: 40px;
                box-shadow: 0 10px 30px rgba(0,0,0,0.2);
                position: relative;
                overflow: hidden;
            ">
                <div style="
                    position: absolute;
                    top: 0;
                    left: 0;
                    right: 0;
                    bottom: 0;
                    background: url('data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22%3E%3Cdefs%3E%3Cpattern id=%22grain%22 width=%22100%22 height=%22100%22 patternUnits=%22userSpaceOnUse%22%3E%3Ccircle cx=%2225%22 cy=%2225%22 r=%221%22 fill=%22%23ffffff%22 opacity=%220.1%22/%3E%3Ccircle cx=%2275%22 cy=%2275%22 r=%221%22 fill=%22%23ffffff%22 opacity=%220.1%22/%3E%3Ccircle cx=%2275%22 cy=%2225%22 r=%220.5%22 fill=%22%23ffffff%22 opacity=%220.1%22/%3E%3Ccircle cx=%2225%22 cy=%2275%22 r=%220.5%22 fill=%22%23ffffff%22 opacity=%220.1%22/%3E%3C/pattern%3E%3C/defs%3E%3Crect width=%22100%22 height=%22100%22 fill=%22url(%23grain)%22/%3E%3C/svg%3E');
                "></div>
            </div>
            """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("ğŸ“Š ìœ ë‹ˆë²„ìŠ¤ ì„¤ì •")
    
    # ê¸°ë³¸ í‹°ì»¤ ëª©ë¡
    default_tickers = [
        'XLC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLK', 'XLU',
        'SPYV', 'SPYG', 'VYM', 'RSP', 'USMV', 'SPMO', 'SPY', 'QQQ', 'IDEV', 'IEMG', 'ACWI', 'PTF', 'GRID', 'BOTZ', 'SMH', 'ITB', 
        'EWJ', 'IXUS', 'VGK', 'MCHI', 'EPP' 
    ]
    
    tickers_input = st.sidebar.text_area(
        "ì¢…ëª© í‹°ì»¤ (ì‰¼í‘œë¡œ êµ¬ë¶„)",
        value=", ".join(default_tickers[:35]),
        help="ì˜ˆì‹œ: SPY, QQQ, XLK",
        height=70
    )
    
    tickers = [ticker.strip().upper() for ticker in tickers_input.split(",") if ticker.strip()]

    # ë°ì´í„° ê³µë°± ë³´ì™„ ì˜µì…˜ ì¶”ê°€
    fill_gaps = st.sidebar.checkbox(
        "ë°ì´í„° ê³µë°± ë³´ì™„ ì˜µì…˜",
        value=True,
        help="ìì‚°ì˜ ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš°, ìœ ì‚¬í•œ ìì‚°ìœ¼ë¡œ ìë™ ëŒ€ì²´"
    )

    # ë‚ ì§œ ì„¤ì • - ê°„ê²© ì¡°ì •

    st.markdown("""
        <style>
        /* date input ë¼ë²¨ í¬ê¸° ì¤„ì´ê¸° */
        .stDateInput label {
            font-size: 13.5px !important;
        }
        /* ë‹¬ë ¥ ë‚´ë¶€ í…ìŠ¤íŠ¸ í¬ê¸° ì¤„ì´ê¸° */
        .stDateInput input {
            font-size: 13.5px !important;
        }
        </style>
    """, unsafe_allow_html=True)
    st.sidebar.markdown('<div style="margin-top: 15px;"></div>', unsafe_allow_html=True)
    
    col1, col2 = st.sidebar.columns(2)
    with col1:
        start_date = st.date_input(
            "ì‹œì‘ ë‚ ì§œ",
            value=dt.date(2011, 1, 1),
            min_value=dt.date(2005, 1, 1),
            max_value=dt.date.today()
        )
    
    with col2:
        end_date = st.date_input(
            "ì¢…ë£Œ ë‚ ì§œ",
            value=dt.date.today(),
            min_value=start_date,
            max_value=dt.date.today()
        )

    # ë°±í…ŒìŠ¤íŒ… íŒŒë¼ë¯¸í„°
    st.sidebar.markdown('<div style="margin-top: 10px;"></div>', unsafe_allow_html=True)
    st.sidebar.subheader("ë°±í…ŒìŠ¤íŒ… ì„¤ì •")

    window = st.sidebar.slider("ëª¨ë©˜í…€ ìœˆë„ìš° (ê°œì›”)", 3, 12, 6)
    top_n_stocks = st.sidebar.slider("ì„ íƒ ì¢…ëª© ìˆ˜", 5, min(25, len(tickers)), min(15, len(tickers)))
    upper_bound = st.sidebar.slider("ìµœëŒ€ ê°€ì¤‘ì¹˜ (%)", 5, 20, 20) / 100
    lower_bound = st.sidebar.slider("ìµœì†Œ ê°€ì¤‘ì¹˜ (%)", 1, 5, 1) / 100

    benchmark_display = st.sidebar.selectbox(
        "ë²¤ì¹˜ë§ˆí¬",
        list(BENCHMARK_OPTIONS.keys()),
        index=2
    )
    benchmark_ticker = BENCHMARK_OPTIONS[benchmark_display]

    # ì‹¤í–‰ ë²„íŠ¼
    if st.sidebar.button("ğŸš€ í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±", type="primary"):
        if len(tickers) < 5:
            st.error("ìµœì†Œ 5ê°œ ì´ìƒì˜ í‹°ì»¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        try:
            with st.spinner("ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì¤‘..."):
                #ë°ì´í„° ë¡œë”
                monthly_df, substitution_log = load_universe_data_enhanced(
                    tickers, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), fill_gaps
                )

                if monthly_df is None:
                    st.error("ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    return

                # ëŒ€ì²´ ë¡œê·¸ í‘œì‹œ
                if substitution_log:
                    st.subheader("ğŸ”„ ë°ì´í„° ëŒ€ì²´ ë¡œê·¸")
                    substitute_df = pd.DataFrame([
                        {
                            'ì›ë³¸ ìì‚°': original,
                            'ëŒ€ì²´ ìì‚°': info['substitute'],
                            'ëŒ€ì²´ ì‹œì‘ì¼': info['substitute_start'].strftime('%Y-%m-%d') if info['substitute_start'] else 'N/A',
                            'ëŒ€ì²´ ë°©ì‹': 'ìœ ì‚¬ìì‚°' if info['method'] == 'similar_asset' else 'ê¸°íƒ€'
                        }
                        for original, info in substitution_log.items()
                    ])
                    st.dataframe(substitute_df, use_container_width=True, hide_index=True)

                # ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°
                benchmark_data = load_benchmark_data(
                    benchmark_ticker, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')
                )

                if benchmark_data is None:
                    st.error("ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    return

                if isinstance(benchmark_data, pd.Series):
                    benchmark_df = benchmark_data
                elif isinstance(benchmark_data, pd.DataFrame):
                    benchmark_df = benchmark_data.iloc[:, 0]
                else:
                    st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° íƒ€ì…: {type(benchmark_data)}")
                    return

                # ê³µí†µ ê¸°ê°„ ì¡°ì •
                common_start = max(monthly_df.index[0], benchmark_df.index[0])
                common_end = min(monthly_df.index[-1], benchmark_df.index[-1])

                monthly_df = monthly_df.loc[common_start:common_end]
                benchmark_df = benchmark_df.loc[common_start:common_end]

                stock_returns = monthly_df.pct_change().dropna()
                benchmark_returns = benchmark_df.pct_change().dropna()

                # ë””ë²„ê¹… ì •ë³´
                st.write(f"ìì‚° ë°ì´í„° ê¸¸ì´: {len(stock_returns)}")
                st.write(f"ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ê¸¸ì´: {len(benchmark_returns)}")
                st.write(f"ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° íƒ€ì…: {type(benchmark_returns)}")

            with st.spinner("ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ ì¤‘..."):
                # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
                portfolio_returns, weights_composition = run_backtest(
                    stock_returns, window, top_n_stocks, upper_bound, lower_bound
                )

                # í¬íŠ¸í´ë¦¬ì˜¤ì™€ ë²¤ì¹˜ë§ˆí¬ì˜ ê³µí†µ ì¸ë±ìŠ¤ ì°¾ê¸°
                common_index = portfolio_returns.index.intersection(benchmark_returns.index)

                # ê³µí†µ ì¸ë±ìŠ¤ë¡œ ì¬ì •ë ¬
                portfolio_returns_aligned = portfolio_returns.loc[common_index]
                benchmark_returns_aligned = benchmark_returns.loc[common_index]

                # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
                #st.write(f"í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ë°ì´í„° í¬ì¸íŠ¸: {len(portfolio_returns_aligned)}")
                #st.write(f"ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥  ë°ì´í„° í¬ì¸íŠ¸: {len(benchmark_returns_aligned)}")
                #st.write(f"ê³µí†µ ê¸°ê°„: {common_index[0].strftime('%Y-%m-%d')} ~ {common_index[-1].strftime('%Y-%m-%d')}")

                # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
                portfolio_metrics = calculate_performance_metrics(portfolio_returns_aligned, benchmark_returns_aligned)
                benchmark_metrics = calculate_performance_metrics(benchmark_returns_aligned)
                
                # íšŒì „ìœ¨ ê³„ì‚°
                portfolio_turnover = calculate_portfolio_turnover(weights_composition)


            # ê²°ê³¼ í‘œì‹œ
            st.success(f"ë°±í…ŒìŠ¤íŒ… ë° í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„± ì™„ë£Œ! ({common_index[0].strftime('%Y-%m')} ~ {common_index[-1].strftime('%Y-%m')})")

            # ì„±ê³¼ ì§€í‘œ í…Œì´ë¸”
            col1, col2 = st.columns(2)

            with col1:
                st.subheader("ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼")
                benchmark_name = BENCHMARK_NAMES.get(benchmark_ticker, benchmark_ticker)

                # ì•ˆì „í•œ í¬ë§·íŒ… (ì´ì œ ëª¨ë“  ê°’ì´ floatì´ë¯€ë¡œ ì•ˆì „í•¨)
                metrics_df = pd.DataFrame({
                    'í¬íŠ¸í´ë¦¬ì˜¤': [
                        f"{portfolio_metrics['total_return']:.2%}",
                        f"{portfolio_metrics['annualized_return']:.2%}",
                        f"{portfolio_metrics['volatility']:.2%}",
                        f"{portfolio_metrics['sharpe_ratio']:.2f}",
                        f"{portfolio_metrics['max_drawdown']:.2%}",
                        f"{portfolio_metrics['tracking_error']:.2%}"
                    ],
                    f'{benchmark_name}': [
                        f"{benchmark_metrics['total_return']:.2%}",
                        f"{benchmark_metrics['annualized_return']:.2%}",
                        f"{benchmark_metrics['volatility']:.2%}",
                        f"{benchmark_metrics['sharpe_ratio']:.2f}",
                        f"{benchmark_metrics['max_drawdown']:.2%}",
                        "N/A"
                    ]
                }, index=['ì´ ìˆ˜ìµë¥ ', 'ì—°í‰ê·  ìˆ˜ìµë¥ ', 'ì—°ë³€ë™ì„±', 'ìƒ¤í”„ ë¹„ìœ¨', 'ìµœëŒ€ ë‚™í­', 'ì¶”ì ì˜¤ì°¨'])

                st.dataframe(metrics_df, use_container_width=True)

            with col2:
                st.subheader("ğŸ“‹ ë°±í…ŒìŠ¤íŒ… ì •ë³´")
                info_df = pd.DataFrame({
                    'í•­ëª©': ['ë¶„ì„ ê¸°ê°„', 'ì´ ì¢…ëª© ìˆ˜', 'ì„ íƒ ì¢…ëª© ìˆ˜', 'ë¦¬ë°¸ëŸ°ì‹±', 'ê°€ì¤‘ì¹˜ ë²”ìœ„', 'ì—°ê°„ íšŒì „ìœ¨'],
                    'ê°’': [
                        f"{common_index[0].strftime('%Y-%m')} ~ {common_index[-1].strftime('%Y-%m')}",
                        f"{len(tickers)}ê°œ",
                        f"{top_n_stocks}ê°œ",
                        "ë§¤ì›”",
                        f"{lower_bound:.1%} ~ {upper_bound:.1%}",
                        f"{portfolio_turnover:.1%}"
                    ]
                })
                st.dataframe(info_df, use_container_width=True, hide_index=True)

            # í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±ê³¼ ë¦¬ë°¸ëŸ°ì‹± ì •ë³´
            st.subheader(f"ğŸ“° í¬íŠ¸í´ë¦¬ì˜¤ ì—…ë°ì´íŠ¸ ({dt.date.today().strftime('%Y-%m')} ê¸°ì¤€)")

            if weights_composition:
                # ìµœê·¼ ë‘ ê°œ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
                recent_dates = sorted(weights_composition.keys())
                latest_date = recent_dates[-1]
                previous_date = recent_dates[-2] if len(recent_dates) > 1 else None

                current_weights = weights_composition[latest_date]
                previous_weights = weights_composition[previous_date] if previous_date else None

                col1, col2 = st.columns(2)

                with col1:
                    # í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±
                    st.write(f"**ğŸ“•{latest_date.strftime('%Y-%m-%d')} ë¦¬ë°¸ëŸ°ì‹± ì•ˆ**")

                    current_df = pd.DataFrame([
                        {'ì¢…ëª©': stock, 'ë¹„ì¤‘': f"{weight:.2%}"}
                        for stock, weight in sorted(current_weights.items(), key=lambda x: x[1], reverse=True)
                    ])
                    st.dataframe(current_df, use_container_width=True, hide_index=True)

                    # íŒŒì´ ì°¨íŠ¸
                    fig_pie = px.pie(
                        values=list(current_weights.values()),
                        names=list(current_weights.keys()),
                        title="ğŸ“’í˜„ì¬ ë¹„ì¤‘ ë¶„í¬"
                    )
                    fig_pie.update_layout(template="plotly_dark", height=400)
                    st.plotly_chart(fig_pie, use_container_width=True)

                with col2:
                    # ë¦¬ë°¸ëŸ°ì‹± ë³€í™”
                    if previous_weights:
                        st.write(f"**ğŸ“™ì „ì›” ëŒ€ë¹„ ë¦¬ë°¸ëŸ°ì‹± ë³€í™”** ({previous_date.strftime('%Y-%m-%d')} â†’ {latest_date.strftime('%Y-%m-%d')})")

                        changes = get_rebalancing_changes(current_weights, previous_weights)

                        if changes:
                            rebalancing_data = []
                            for stock, change_info in sorted(changes.items(), key=lambda x: abs(x[1]['change']), reverse=True):
                                action_emoji = "ğŸ“ˆ" if change_info['action'] == 'INCREASE' else "ğŸ“‰" if change_info['action'] == 'DECREASE' else "â¡ï¸"
                                rebalancing_data.append({
                                    'ì¢…ëª©': f"{action_emoji} {stock}",
                                    'ì´ì „ ë¹„ì¤‘': f"{change_info['previous']:.2%}",
                                    'í˜„ì¬ ë¹„ì¤‘': f"{change_info['current']:.2%}",
                                    'ë³€í™”': f"{change_info['change']:+.2%}"
                                })

                            rebalancing_df = pd.DataFrame(rebalancing_data)
                            st.dataframe(rebalancing_df, use_container_width=True, hide_index=True)

                            # ë¦¬ë°¸ëŸ°ì‹± ë³€í™” ì‹œê°í™”
                            stocks = list(changes.keys())
                            changes_values = [changes[stock]['change'] for stock in stocks]
                            colors = ['deeppink' if x > 0 else 'royalblue' for x in changes_values]

                            fig_rebal = go.Figure(data=[
                                go.Bar(x=stocks, y=[x*100 for x in changes_values],
                                      marker_color=colors,
                                      text=[f"{x:+.1%}" for x in changes_values],
                                      textposition='auto')
                            ])
                            fig_rebal.update_layout(
                                title="ğŸ“—ë¦¬ë°¸ëŸ°ì‹± ë³€í™” (%p)",
                                xaxis_title="ì¢…ëª©",
                                yaxis_title="ë¹„ì¤‘ ë³€í™” (%p)",
                                template="plotly_dark",
                                height=400
                            )
                            st.plotly_chart(fig_rebal, use_container_width=True)
                        else:
                            st.info("ì´ì „ ì›” ëŒ€ë¹„ ìœ ì˜ë¯¸í•œ ë¦¬ë°¸ëŸ°ì‹± ë³€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info("ë¹„êµí•  ì´ì „ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            # ì°¨íŠ¸ ìƒì„±
            st.subheader("ğŸ“ˆ ì„±ê³¼ ë¶„ì„")
            benchmark_name = BENCHMARK_NAMES.get(benchmark_ticker, benchmark_ticker)

            # ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
            st.write("=== ì‹œê°í™” ë°ì´í„° ê²€ì¦ ===")
            st.write(f"í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ìƒ˜í”Œ: {portfolio_returns_aligned.head(3).values}")
            st.write(f"ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥  ìƒ˜í”Œ: {benchmark_returns_aligned.head(3).values}")
            st.write(f"í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  NaN ê°œìˆ˜: {portfolio_returns_aligned.isna().sum()}")
            st.write(f"ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥  NaN ê°œìˆ˜: {benchmark_returns_aligned.isna().sum()}")

            # ëˆ„ì  ìˆ˜ìµë¥ 
            cumulative_portfolio = (1 + portfolio_returns_aligned).cumprod() - 1
            cumulative_benchmark = (1 + benchmark_returns_aligned).cumprod() - 1

            fig1 = go.Figure()
            fig1.add_trace(go.Scatter(
                x=cumulative_portfolio.index,
                y=cumulative_portfolio * 100,
                mode='lines',
                name='í¬íŠ¸í´ë¦¬ì˜¤',
                line=dict(color='deeppink', width=2)
            ))
            fig1.add_trace(go.Scatter(
                x=cumulative_benchmark.index,
                y=cumulative_benchmark * 100,
                mode='lines',
                name=benchmark_name,
                line=dict(color='royalblue', width=2, dash='dash')
            ))
            fig1.update_layout(
                title="ëˆ„ì  ìˆ˜ìµë¥  ë¹„êµ",
                xaxis_title="ë‚ ì§œ",
                yaxis_title="ëˆ„ì  ìˆ˜ìµë¥  (%)",
                hovermode='x unified',
                template="plotly_dark"
            )
            st.plotly_chart(fig1, use_container_width=True)

            # 4ê°œ ì°¨íŠ¸ 2x2ë¡œ ë°°ì¹˜
            col1, col2 = st.columns(2)

            with col1:
                # ì›”ë³„ ìˆ˜ìµë¥  ë¶„í¬
                fig2 = go.Figure()
                fig2.add_trace(go.Histogram(
                    x=portfolio_returns_aligned * 100,
                    name='í¬íŠ¸í´ë¦¬ì˜¤',
                    opacity=0.7,
                    marker_color='deeppink',
                    nbinsx=20
                ))
                fig2.add_trace(go.Histogram(
                    x=benchmark_returns_aligned * 100,
                    name=benchmark_name,
                    opacity=0.7,
                    marker_color='royalblue',
                    nbinsx=20
                ))
                fig2.update_layout(
                    title="ì›”ë³„ ìˆ˜ìµë¥  ë¶„í¬",
                    xaxis_title="ì›”ë³„ ìˆ˜ìµë¥  (%)",
                    yaxis_title="ë¹ˆë„",
                    barmode='overlay',
                    template="plotly_dark"
                )
                st.plotly_chart(fig2, use_container_width=True)

            with col2:
                # ë¡¤ë§ ìƒ¤í”„ ë¹„ìœ¨ (12ê°œì›”)
                rolling_sharpe_portfolio = portfolio_returns_aligned.rolling(12).mean() / portfolio_returns_aligned.rolling(12).std() * np.sqrt(12)
                rolling_sharpe_benchmark = benchmark_returns_aligned.rolling(12).mean() / benchmark_returns_aligned.rolling(12).std() * np.sqrt(12)

                fig3 = go.Figure()
                fig3.add_trace(go.Scatter(
                    x=rolling_sharpe_portfolio.index,
                    y=rolling_sharpe_portfolio,
                    mode='lines',
                    name='í¬íŠ¸í´ë¦¬ì˜¤',
                    line=dict(color='deeppink', width=2)
                ))
                fig3.add_trace(go.Scatter(
                    x=rolling_sharpe_benchmark.index,
                    y=rolling_sharpe_benchmark,
                    mode='lines',
                    name=benchmark_name,
                    line=dict(color='royalblue', width=2, dash='dash')
                ))
                fig3.update_layout(
                    title="12ê°œì›” ë¡¤ë§ ìƒ¤í”„ ë¹„ìœ¨",
                    xaxis_title="ë‚ ì§œ",
                    yaxis_title="ìƒ¤í”„ ë¹„ìœ¨",
                    hovermode='x unified',
                    template="plotly_dark"
                )
                st.plotly_chart(fig3, use_container_width=True)

            # ë‚™í­ ë¹„êµ ì°¨íŠ¸
            portfolio_cumulative = (1 + portfolio_returns_aligned).cumprod()
            portfolio_running_max = portfolio_cumulative.expanding().max()
            portfolio_drawdown = (portfolio_cumulative - portfolio_running_max) / portfolio_running_max

            benchmark_cumulative = (1 + benchmark_returns_aligned).cumprod()
            benchmark_running_max = benchmark_cumulative.expanding().max()
            benchmark_drawdown = (benchmark_cumulative - benchmark_running_max) / benchmark_running_max

            fig4 = go.Figure()
            fig4.add_trace(go.Scatter(
                x=portfolio_drawdown.index,
                y=portfolio_drawdown * 100,
                fill='tonexty',
                mode='lines',
                name='í¬íŠ¸í´ë¦¬ì˜¤',
                line=dict(color='deeppink', width=1),
                fillcolor='rgba(255,20,147,0.3)'
            ))
            fig4.add_trace(go.Scatter(
                x=benchmark_drawdown.index,
                y=benchmark_drawdown * 100,
                fill='tonexty',
                mode='lines',
                name=benchmark_name,
                line=dict(color='royalblue', width=1),
                fillcolor='rgba(65,105,225,0.3)'
            ))
            fig4.update_layout(
                title="ë‚™í­ (Drawdown) ë¹„êµ",
                xaxis_title="ë‚ ì§œ",
                yaxis_title="ë‚™í­ (%)",
                hovermode='x unified',
                template="plotly_dark"
            )
            st.plotly_chart(fig4, use_container_width=True)



            
            # ì—°ë„ë³„ ë° ì›”ë³„ ì„±ê³¼ ì°¨íŠ¸
            st.subheader("ğŸ“… ì—°ë„ë³„ ë° ì›”ë³„ ì„±ê³¼")

            fig_yearly, fig_monthly = create_performance_charts(
                portfolio_returns_aligned, benchmark_returns_aligned, benchmark_name
            )

            col1, col2 = st.columns(2)
            with col1:
                st.plotly_chart(fig_yearly, use_container_width=True)
            with col2:
                st.plotly_chart(fig_monthly, use_container_width=True)




            # í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± íˆìŠ¤í† ë¦¬
            st.subheader("ğŸ“‘ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± íˆìŠ¤í† ë¦¬")

            if weights_composition:
                recent_dates = sorted(weights_composition.keys())[-5:]  # ìµœê·¼ 5ê°œì›”

                for date_key in recent_dates:
                    weights = weights_composition[date_key]

                    with st.expander(f"{date_key.strftime('%Y-%m-%d')} í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±"):
                        weights_df = pd.DataFrame([
                            {'ì¢…ëª©': stock, 'ê°€ì¤‘ì¹˜': f"{weight:.2%}"}
                            for stock, weight in sorted(weights.items(), key=lambda x: x[1], reverse=True)
                        ])

                        col1, col2 = st.columns([2, 1])
                        with col1:
                            st.dataframe(weights_df, use_container_width=True, hide_index=True)

                        with col2:
                            # íŒŒì´ ì°¨íŠ¸
                            fig_pie = px.pie(
                                values=list(weights.values()),
                                names=list(weights.keys()),
                                title="ê°€ì¤‘ì¹˜ ë¶„í¬"
                            )
                            fig_pie.update_layout(template="plotly_dark", height=300)
                            st.plotly_chart(fig_pie, use_container_width=True)

        except Exception as e:
            st.error(f"ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            import traceback
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

if __name__ == "__main__":
    main()
