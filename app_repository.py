# -*- coding: utf-8 -*-
"""APP_repository.ipynb

generated by Colab.
"""

# Enhanced app.py with data gap filling functionality
import streamlit as st
import yfinance as yf
import numpy as np
import pandas as pd
from datetime import datetime
import datetime as dt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
from scipy.stats import pearsonr
import warnings
warnings.filterwarnings('ignore')


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Portfolio Backtesting App",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë²¤ì¹˜ë§ˆí¬ ì´ë¦„ ë§¤í•‘
BENCHMARK_NAMES = {
    'SPY': 'S&P 500 ì§€ìˆ˜',
    'QQQ': 'Nasdaq 100 ì§€ìˆ˜',
    'ACWI': 'MSCI ACWI ì§€ìˆ˜'
}

# ë²¤ì¹˜ë§ˆí¬ ì˜µì…˜ (í‘œì‹œìš©)
BENCHMARK_OPTIONS = {
    'S&P 500 ì§€ìˆ˜': 'SPY',
    'Nasdaq 100 ì§€ìˆ˜': 'QQQ',
    'MSCI ACWI ì§€ìˆ˜': 'ACWI'
}

# ìœ ì‚¬ ìì‚° ë§¤í•‘ (ìƒˆë¡œìš´ ETF -> ê³¼ê±°ì— ì¡´ì¬í–ˆë˜ ìœ ì‚¬ ìì‚°)
SIMILAR_ASSETS_MAP = {
    # ì„¹í„° ETF ë§¤í•‘
    'XLC': ['XTL', 'IYZ', 'VNQ'],  # Communication Services -> Telecom/Tech/REITs
    'XLY': ['RTH', 'XRT', 'VCR'],  # Consumer Discretionary -> Retail
    'XLP': ['VDC', 'PBJ', 'SZK'],  # Consumer Staples
    'XLE': ['VDE', 'IYE', 'DIG'],  # Energy
    'XLF': ['VFH', 'IYF', 'KBE'],  # Financials
    'XLV': ['VHT', 'IYH', 'PJP'],  # Healthcare
    'XLI': ['VIS', 'IYJ', 'PPA'],  # Industrials
    'XLB': ['VAW', 'IYM', 'SLX'],  # Materials
    'XLK': ['VGT', 'IYW', 'QQQ'],  # Technology
    'XLU': ['VPU', 'IDU', 'PUI'],  # Utilities

    # ìŠ¤íƒ€ì¼ ETF ë§¤í•‘
    'SPYV': ['IVE', 'VTV', 'DVY'],  # S&P 500 Value
    'SPYG': ['IVW', 'VUG', 'MGK'],  # S&P 500 Growth
    'VYM': ['DVY', 'VTV', 'SCHD'],  # High Dividend Yield
    'RSP': ['EQL', 'EWRS', 'SPY'],  # Equal Weight S&P 500
    'USMV': ['SPLV', 'EFAV', 'SPY'],  # Low Volatility
    'SPMO': ['MTUM', 'PDP', 'QQQ'],  # Momentum

    # êµ­ì œ ETF ë§¤í•‘
    'IDEV': ['EFA', 'VEA', 'ACWX'],  # Developed Markets
    'IEMG': ['EEM', 'VWO', 'SCHE'],  # Emerging Markets
}

# ëŒ€ì²´ ìì‚° í’€ (ì—­ì‚¬ê°€ ê¸´ ìì‚°ë“¤)
FALLBACK_ASSETS = {
    'large_cap_growth': ['QQQ', 'VUG', 'IVW'],
    'large_cap_value': ['VTV', 'IVE', 'DVY'],
    'small_cap': ['IWM', 'VB', 'IJR'],
    'international_dev': ['EFA', 'VEA', 'ACWX'],
    'international_em': ['EEM', 'VWO', 'DEM'],
    'sectors': ['XLK', 'XLF', 'XLV', 'XLE', 'XLI'],
    'broad_market': ['SPY', 'VTI', 'ITOT']
}

def get_asset_classification(ticker):
    """ìì‚° ë¶„ë¥˜ í•¨ìˆ˜"""
    growth_etfs = ['SPYG', 'VUG', 'IVW', 'MGK', 'QQQ', 'XLK']
    value_etfs = ['SPYV', 'VTV', 'IVE', 'DVY', 'VYM']
    international_etfs = ['IDEV', 'EFA', 'VEA', 'IEMG', 'EEM', 'VWO']
    sector_etfs = ['XLC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLK', 'XLU']

    if ticker in growth_etfs:
        return 'large_cap_growth'
    elif ticker in value_etfs:
        return 'large_cap_value'
    elif ticker in international_etfs:
        return 'international_dev' if ticker in ['IDEV', 'EFA', 'VEA'] else 'international_em'
    elif ticker in sector_etfs:
        return 'sectors'
    else:
        return 'broad_market'

def find_best_substitute(target_ticker, available_data, start_date, end_date, min_correlation=0.7):
    """ìµœì ì˜ ëŒ€ì²´ ìì‚° ì°¾ê¸°"""

    # 1ë‹¨ê³„: ë¯¸ë¦¬ ì •ì˜ëœ ìœ ì‚¬ ìì‚° í™•ì¸
    if target_ticker in SIMILAR_ASSETS_MAP:
        candidates = SIMILAR_ASSETS_MAP[target_ticker]

        for candidate in candidates:
            try:
                candidate_data = yf.download(candidate, start=start_date, end=end_date)['Close']
                if len(candidate_data) > 252:  # ìµœì†Œ 1ë…„ ë°ì´í„°
                    # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒê´€ê´€ê³„ í™•ì¸ (ê²¹ì¹˜ëŠ” ê¸°ê°„ì´ ìˆë‹¤ë©´)
                    if candidate in available_data.columns:
                        overlap_data = available_data[[candidate]].dropna()
                        if len(overlap_data) > 50:  # ì¶©ë¶„í•œ ê²¹ì¹˜ëŠ” ë°ì´í„°
                            return candidate, candidate_data
                    else:
                        return candidate, candidate_data
            except:
                continue

    # 2ë‹¨ê³„: ìì‚° ë¶„ë¥˜ì— ë”°ë¥¸ ëŒ€ì²´ ìì‚° ì°¾ê¸°
    asset_class = get_asset_classification(target_ticker)
    fallback_candidates = FALLBACK_ASSETS.get(asset_class, FALLBACK_ASSETS['broad_market'])

    best_candidate = None
    best_data = None
    best_correlation = 0

    for candidate in fallback_candidates:
        if candidate == target_ticker:
            continue

        try:
            candidate_data = yf.download(candidate, start=start_date, end=end_date)['Close']
            if len(candidate_data) > 252:  # ìµœì†Œ 1ë…„ ë°ì´í„°

                # ê¸°ì¡´ í¬íŠ¸í´ë¦¬ì˜¤ ìì‚°ë“¤ê³¼ì˜ ìƒê´€ê´€ê³„ í™•ì¸
                if len(available_data.columns) > 0:
                    # ê³µí†µ ê¸°ê°„ì—ì„œ ìƒê´€ê´€ê³„ ê³„ì‚°
                    common_period = candidate_data.index.intersection(available_data.index)
                    if len(common_period) > 50:
                        candidate_returns = candidate_data.loc[common_period].pct_change().dropna()
                        portfolio_returns = available_data.loc[common_period].mean(axis=1).pct_change().dropna()

                        # ê³µí†µ ì¸ë±ìŠ¤ë¡œ ì •ë ¬
                        common_idx = candidate_returns.index.intersection(portfolio_returns.index)
                        if len(common_idx) > 30:
                            corr, _ = pearsonr(candidate_returns.loc[common_idx],
                                             portfolio_returns.loc[common_idx])

                            if corr > best_correlation and corr > min_correlation:
                                best_correlation = corr
                                best_candidate = candidate
                                best_data = candidate_data

                # ì²« ë²ˆì§¸ í›„ë³´ê°€ ì—†ë‹¤ë©´ ì¼ë‹¨ ì„ íƒ
                if best_candidate is None:
                    best_candidate = candidate
                    best_data = candidate_data
                    break

        except Exception as e:
            continue

    return best_candidate, best_data

def fill_missing_data(tickers, start_date, end_date, fill_gaps=True):
    """ë°ì´í„° ê³µë°± ì±„ìš°ê¸°"""

    st.info("ğŸ“Š ë°ì´í„° ë¡œë”© ë° ê³µë°± ë¶„ì„ ì¤‘...")

    # ì›ë³¸ ë°ì´í„° ë¡œë“œ ì‹œë„
    original_data = {}
    missing_tickers = []
    data_info = {}

    for ticker in tickers:
        try:
            data = yf.download(ticker, start=start_date, end=end_date)['Close']

            if isinstance(data, pd.Series):
                data = data.to_frame(name=ticker)

            # ë°ì´í„° í’ˆì§ˆ í™•ì¸
            data_start = data.first_valid_index()
            data_end = data.last_valid_index()
            data_length = len(data.dropna())

            # ëª©í‘œ ì‹œì‘ì¼ê³¼ ì‹¤ì œ ë°ì´í„° ì‹œì‘ì¼ ë¹„êµ
            target_start = pd.to_datetime(start_date)

            if data_start is None or data_length < 50:
                missing_tickers.append(ticker)
                st.warning(f"âŒ {ticker}: ë°ì´í„° ë¶€ì¡± (ê¸¸ì´: {data_length})")
            elif data_start > target_start + pd.DateOffset(years=1):
                missing_tickers.append(ticker)
                st.warning(f"âš ï¸ {ticker}: ì‹œì‘ì¼ ë¶€ì¡± (ëª©í‘œ: {target_start.strftime('%Y-%m')}, ì‹¤ì œ: {data_start.strftime('%Y-%m')})")
                data_info[ticker] = {
                    'original_data': data,
                    'start_gap': (data_start - target_start).days,
                    'needs_filling': True
                }
            else:
                original_data[ticker] = data
                data_info[ticker] = {
                    'original_data': data,
                    'start_gap': 0,
                    'needs_filling': False
                }
                st.success(f"âœ… {ticker}: ë°ì´í„° ì–‘í˜¸ ({data_start.strftime('%Y-%m')} ~ {data_end.strftime('%Y-%m')})")

        except Exception as e:
            missing_tickers.append(ticker)
            st.error(f"âŒ {ticker}: ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ - {str(e)}")

    if not fill_gaps or len(missing_tickers) == 0:
        if len(original_data) > 0:
            combined_data = pd.concat(original_data.values(), axis=1)
            combined_data.columns = original_data.keys()
            return combined_data.resample('ME').last().dropna(), {}
        else:
            return None, {}

    # ëŒ€ì²´ ìì‚° ì°¾ê¸° ë° ë°ì´í„° ê²°í•©
    st.info("ğŸ”„ ëŒ€ì²´ ìì‚° ê²€ìƒ‰ ë° ë°ì´í„° ê²°í•© ì¤‘...")

    substitution_log = {}
    enhanced_data = original_data.copy()

    # ê¸°ì¡´ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ê²°í•©
    if len(enhanced_data) > 0:
        available_data = pd.concat(enhanced_data.values(), axis=1)
        available_data.columns = enhanced_data.keys()
    else:
        available_data = pd.DataFrame()

    for ticker in missing_tickers:
        st.write(f"ğŸ” {ticker} ëŒ€ì²´ ìì‚° ê²€ìƒ‰ ì¤‘...")

        substitute_ticker, substitute_data = find_best_substitute(
            ticker, available_data, start_date, end_date
        )

        if substitute_ticker and substitute_data is not None:
            # ëŒ€ì²´ ë°ì´í„° ì²˜ë¦¬
            if isinstance(substitute_data, pd.Series):
                substitute_data = substitute_data.to_frame(name=substitute_ticker)

            # ì›ë³¸ í‹°ì»¤ ì´ë¦„ìœ¼ë¡œ ì»¬ëŸ¼ëª… ë³€ê²½
            substitute_df = substitute_data.copy()
            substitute_df.columns = [ticker]

            enhanced_data[ticker] = substitute_df
            substitution_log[ticker] = {
                'substitute': substitute_ticker,
                'original_start': data_info.get(ticker, {}).get('original_data', pd.DataFrame()).first_valid_index(),
                'substitute_start': substitute_data.first_valid_index(),
                'method': 'similar_asset'
            }

            st.success(f"âœ… {ticker} â†’ {substitute_ticker} ëŒ€ì²´ ì™„ë£Œ")

            # available_data ì—…ë°ì´íŠ¸
            if len(available_data) == 0:
                available_data = substitute_df
            else:
                available_data = pd.concat([available_data, substitute_df], axis=1)
        else:
            st.error(f"âŒ {ticker}: ì ì ˆí•œ ëŒ€ì²´ ìì‚°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ìµœì¢… ë°ì´í„° ê²°í•©
    if len(enhanced_data) > 0:
        final_data = pd.concat(enhanced_data.values(), axis=1)
        final_data.columns = enhanced_data.keys()

        # ì›”ë§ ë¦¬ìƒ˜í”Œë§
        monthly_data = final_data.resample('ME').last().dropna()

        st.success(f"ğŸ‰ ìµœì¢… ë°ì´í„°ì…‹ ì™„ì„±: {len(monthly_data.columns)}ê°œ ìì‚°, {len(monthly_data)}ê°œì›” ë°ì´í„°")

        return monthly_data, substitution_log
    else:
        st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, {}

# ìºì‹œëœ ë°ì´í„° ë¡œë” - ìˆ˜ì •ëœ ë²„ì „
@st.cache_data
def load_universe_data_enhanced(tickers, start_date, end_date, fill_gaps=True):
    """í–¥ìƒëœ ìœ ë‹ˆë²„ìŠ¤ ë°ì´í„° ë¡œë”"""
    return fill_missing_data(tickers, start_date, end_date, fill_gaps)

@st.cache_data
def load_benchmark_data(ticker, start_date, end_date):
    """ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë¡œë“œ"""
    try:
        data = yf.download(ticker, start=start_date, end=end_date)['Close']

        if isinstance(data, pd.Series):
            data = data.to_frame(name=ticker)
        elif isinstance(data, pd.DataFrame) and len(data.columns) == 1:
            data.columns = [ticker]

        monthly_prices = data.resample('ME').last()
        monthly_prices = monthly_prices.dropna()

        if len(monthly_prices.columns) == 1:
            return monthly_prices.iloc[:, 0]
        else:
            return monthly_prices

    except Exception as e:
        st.error(f"ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def adjust_weights_to_bounds(weights, upper_bound, lower_bound, max_iterations=100):
    """ê°€ì¤‘ì¹˜ ì¡°ì • í•¨ìˆ˜"""
    adjusted_weights = weights.copy()

    for iteration in range(max_iterations):
        adjusted_weights = np.minimum(adjusted_weights, upper_bound)
        adjusted_weights = np.maximum(adjusted_weights, lower_bound)

        total_weight = adjusted_weights.sum()

        if abs(total_weight - 1.0) < 1e-6:
            break

        if total_weight > 1.0:
            excess = total_weight - 1.0
            adjustable_mask = adjusted_weights > lower_bound
            if adjustable_mask.sum() > 0:
                reduction = excess * (adjusted_weights / adjusted_weights[adjustable_mask].sum())
                reduction[~adjustable_mask] = 0
                adjusted_weights = adjusted_weights - reduction
                adjusted_weights = np.maximum(adjusted_weights, lower_bound)
        else:
            deficit = 1.0 - total_weight
            adjustable_mask = adjusted_weights < upper_bound
            if adjustable_mask.sum() > 0:
                addition = deficit * (adjusted_weights / adjusted_weights[adjustable_mask].sum())
                addition[~adjustable_mask] = 0
                adjusted_weights = adjusted_weights + addition
                adjusted_weights = np.minimum(adjusted_weights, upper_bound)

    adjusted_weights = adjusted_weights / adjusted_weights.sum()
    return adjusted_weights

def run_backtest(stock_returns, window, top_n_stocks, upper_bound, lower_bound):
    """ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰"""
    portfolio_returns = []
    portfolio_dates = []
    portfolio_composition = {}
    weights_composition = {}
    prev_weights = None

    progress_bar = st.progress(0)
    total_iterations = len(stock_returns) - window

    for i in range(window, len(stock_returns)):
        progress_bar.progress((i - window) / total_iterations)

        current_date = stock_returns.index[i]
        past_returns = stock_returns.iloc[i-window:i]
        momentum_score = (1 + past_returns).prod() - 1

        if i % 1 == 0:  # ë§¤ì›” ë¦¬ë°¸ëŸ°ì‹±
            current_top_stocks = momentum_score.nlargest(top_n_stocks).index.tolist()
            portfolio_composition[current_date] = current_top_stocks

            lookback_period = min(36, i)
            if lookback_period < 12:
                continue

            historical_returns = stock_returns.iloc[i-lookback_period:i][current_top_stocks]
            if len(historical_returns) < 12:
                continue

            cov_matrix = historical_returns.cov()
            sigma_squared = np.diag(cov_matrix.values)
            sigma_squared = np.maximum(sigma_squared, 1e-8)

            momentum_scores = momentum_score[current_top_stocks].values
            momentum_scores = np.maximum(momentum_scores, 0.01)

            inverse_volatility = 1 / np.sqrt(sigma_squared)
            base_weights = inverse_volatility / inverse_volatility.sum()

            adjusted_weights = base_weights * np.sqrt(momentum_scores)
            adjusted_weights = adjusted_weights / adjusted_weights.sum()

            final_weights = adjust_weights_to_bounds(adjusted_weights, upper_bound, lower_bound)

            weights_composition[current_date] = dict(zip(current_top_stocks, final_weights))
            prev_weights = weights_composition[current_date]

        if prev_weights is not None:
            current_stocks = list(prev_weights.keys())
            weights_array = np.array(list(prev_weights.values()))

            available_returns = stock_returns.loc[current_date, current_stocks]

            if not available_returns.isna().any():
                portfolio_return = np.sum(weights_array * available_returns.values)
                portfolio_returns.append(portfolio_return)
                portfolio_dates.append(current_date)
            else:
                portfolio_returns.append(0.0)
                portfolio_dates.append(current_date)

    progress_bar.empty()

    return pd.Series(portfolio_returns, index=portfolio_dates), weights_composition

def safe_convert_to_float(value):
    """ê°’ì„ ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜"""
    try:
        if hasattr(value, 'item'):
            return float(value.item())
        elif hasattr(value, '__array__') and value.ndim == 0:
            return float(value)
        else:
            return float(value)
    except (ValueError, TypeError, AttributeError):
        return 0.0

def calculate_performance_metrics(returns):
    """ì„±ê³¼ ì§€í‘œ ê³„ì‚°"""
    if len(returns) == 0:
        return {
            'total_return': 0.0,
            'annualized_return': 0.0,
            'volatility': 0.0,
            'sharpe_ratio': 0.0,
            'max_drawdown': 0.0
        }

    total_return = safe_convert_to_float((1 + returns).prod() - 1)
    annualized_return = safe_convert_to_float((1 + returns.mean())**12 - 1)
    volatility = safe_convert_to_float(returns.std() * np.sqrt(12))

    sharpe_ratio = annualized_return / volatility if volatility > 0 else 0.0

    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = (cumulative - running_max) / running_max
    max_drawdown = safe_convert_to_float(drawdown.min())

    return {
        'total_return': total_return,
        'annualized_return': annualized_return,
        'volatility': volatility,
        'sharpe_ratio': sharpe_ratio,
        'max_drawdown': max_drawdown
    }

def get_rebalancing_changes(current_weights, previous_weights):
    """ë¦¬ë°¸ëŸ°ì‹± ë³€í™” ê³„ì‚°"""
    all_stocks = set(list(current_weights.keys()) + (list(previous_weights.keys()) if previous_weights else []))

    changes = {}
    for stock in all_stocks:
        current_weight = current_weights.get(stock, 0)
        previous_weight = previous_weights.get(stock, 0) if previous_weights else 0

        change = current_weight - previous_weight
        if abs(change) > 0.001:
            changes[stock] = {
                'previous': previous_weight,
                'current': current_weight,
                'change': change,
                'action': 'INCREASE' if change > 0 else 'DECREASE' if change < 0 else 'HOLD'
            }

    return changes

# ë©”ì¸ ì•±
def main():
    st.title("ğŸ“ˆ Portfolio Backtesting App")
    st.markdown("##### ë§Œë“ ì´: ë°•ì„")
    

    st.markdown(
        '<div style="text-align: right; margin-bottom: 10px;">'
        'Data ì¶œì²˜: <a href="https://finance.yahoo.com/" target="_blank">Yahoo Finance</a>'
        '</div>',
        unsafe_allow_html=True
    )

    # ì•± ì„¤ëª… ì„¹ì…˜ - ì—…ë°ì´íŠ¸
    st.markdown("### ğŸ“‹ ì•± ì†Œê°œ")
    st.markdown("""
    **ì´ ì•±ì€ ë°ì´í„° ê³µë°± ìë™ ë³´ì™„ ê¸°ëŠ¥ì„ ê°–ì¶˜ ëª¨ë©˜í…€ ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ë°±í…ŒìŠ¤íŒ… ë„êµ¬ì…ë‹ˆë‹¤.**

    #### ğŸ¯ ì£¼ìš” ê¸°ëŠ¥
    - **ìì‚° ì„ íƒ**: ì›í•˜ëŠ” ETF, ì£¼ì‹ ë“± ììœ ë¡œìš´ íˆ¬ì ìœ ë‹ˆë²„ìŠ¤ ì„¤ì •
    - **íŒŒë¼ë¯¸í„° ì¡°ì •**: ëª¨ë©˜í…€ ê¸°ê°„, ì„ íƒ ì¢…ëª© ìˆ˜, ìµœëŒ€/ìµœì†Œ ê°€ì¤‘ì¹˜ ë“± ì „ëµ íŒŒë¼ë¯¸í„° ì¡°ì •
    - **ê¸°ê°„ ì„¤ì •**: ë°±í…ŒìŠ¤íŒ… ë¶„ì„ ê¸°ê°„ì„ ììœ ë¡­ê²Œ ì„¤ì • ê°€ëŠ¥
    - **ëª¨ë©˜í…€ ì „ëµ**: ê³¼ê±° ìˆ˜ìµë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒìœ„ ìì‚°ì„ ì„ ë³„í•˜ì—¬ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ êµ¬ì„±
    - **ë¦¬ìŠ¤í¬ ì¡°ì •**: ì—­ë³€ë™ì„± ê°€ì¤‘ì¹˜ì™€ ëª¨ë©˜í…€ ìŠ¤ì½”ì–´ë¥¼ ê²°í•©í•œ ìŠ¤ë§ˆíŠ¸ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”
    - **ì›”ë³„ ë¦¬ë°¸ëŸ°ì‹±**: ë§¤ì›” í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì¬ì¡°ì •í•˜ì—¬ ìµœì ì˜ ìì‚° êµ¬ì„± ìœ ì§€

    #### âœ”ï¸ ë¶„ì„ ê²°ê³¼ ì œê³µ
    - **ì„±ê³¼ ì§€í‘œ**: ìˆ˜ìµë¥ , ë³€ë™ì„±, ìƒ¤í”„ ë¹„ìœ¨, ìµœëŒ€ ë‚™í­ ë“± ì£¼ìš” íˆ¬ì ì§€í‘œ ë¶„ì„
    - **ë²¤ì¹˜ë§ˆí¬ ë¹„êµ**: S&P 500, Nasdaq 100, MSCI ACWI ì§€ìˆ˜ì™€ì˜ ì„±ê³¼ ë¹„êµ
    - **ì‹œê°í™”**: ëˆ„ì  ìˆ˜ìµë¥ , ë¦¬ìŠ¤í¬ ë¶„ì„, í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ë³€í™” ë“± ë‹¤ì–‘í•œ ì°¨íŠ¸ ì œê³µ

    #### ğŸ”§ ë°ì´í„° ê³µë°± ë³´ì™„ ë°©ì‹
    - **ìœ ì‚¬ ìì‚° ë§¤í•‘**: ì„ íƒí•œ ìì‚°ì˜ ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš°, ìœ ì‚¬í•œ íŠ¹ì„±ì„ ê°€ì§„ ëŒ€ì²´ ìì‚°ìœ¼ë¡œ ìë™ ë³´ì™„
    - **ìƒê´€ê´€ê³„ ë¶„ì„**: ê¸°ì¡´ í¬íŠ¸í´ë¦¬ì˜¤ì™€ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ ëŒ€ì²´ ìì‚° ì„ íƒ
    - **ìì‚° ë¶„ë¥˜ë³„ ëŒ€ì²´**: ì„±ì¥ì£¼, ê°€ì¹˜ì£¼, ì„¹í„°ë³„ ë“± ìì‚° íŠ¹ì„±ì— ë”°ë¥¸ ì²´ê³„ì  ëŒ€ì²´
    """)

    st.markdown("---")

    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("ğŸ“Š ìœ ë‹ˆë²„ìŠ¤ ì„¤ì •")

    # ê¸°ë³¸ í‹°ì»¤ ëª©ë¡
    default_tickers = [
        'XLC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLK', 'XLU',
        'SPYV', 'SPYG', 'VYM', 'RSP', 'USMV', 'SPMO', 'SPY', 'QQQ', 'IDEV', 'IEMG', 'ACWI'
    ]

    tickers_input = st.sidebar.text_area(
        "ì¢…ëª© í‹°ì»¤ (ì‰¼í‘œë¡œ êµ¬ë¶„)",
        value=", ".join(default_tickers[:25]),
        help="ì˜ˆì‹œ: SPY, QQQ, XLK",
        height=70
    )

    tickers = [ticker.strip().upper() for ticker in tickers_input.split(",") if ticker.strip()]

    # ë°ì´í„° ê³µë°± ë³´ì™„ ì˜µì…˜ ì¶”ê°€
    fill_gaps = st.sidebar.checkbox(
        "ë°ì´í„° ê³µë°± ë³´ì™„ ì˜µì…˜",
        value=True,
        help="ìì‚°ì˜ ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš°, ìœ ì‚¬í•œ ìì‚°ìœ¼ë¡œ ìë™ ëŒ€ì²´"
    )

    # ë‚ ì§œ ì„¤ì • - ê°„ê²© ì¡°ì •

    st.markdown("""
        <style>
        /* date input ë¼ë²¨ í¬ê¸° ì¤„ì´ê¸° */
        .stDateInput label {
            font-size: 13.5px !important;
        }
        /* ë‹¬ë ¥ ë‚´ë¶€ í…ìŠ¤íŠ¸ í¬ê¸° ì¤„ì´ê¸° */
        .stDateInput input {
            font-size: 13.5px !important;
        }
        </style>
    """, unsafe_allow_html=True)
    st.sidebar.markdown('<div style="margin-top: 15px;"></div>', unsafe_allow_html=True)
    
    col1, col2 = st.sidebar.columns(2)
    with col1:
        start_date = st.date_input(
            "ì‹œì‘ ë‚ ì§œ",
            value=dt.date(2010, 1, 1),
            min_value=dt.date(2005, 1, 1),
            max_value=dt.date.today()
        )
    
    with col2:
        end_date = st.date_input(
            "ì¢…ë£Œ ë‚ ì§œ",
            value=dt.date.today(),
            min_value=start_date,
            max_value=dt.date.today()
        )

    # ë°±í…ŒìŠ¤íŒ… íŒŒë¼ë¯¸í„°
    st.sidebar.markdown('<div style="margin-top: 10px;"></div>', unsafe_allow_html=True)
    st.sidebar.subheader("ë°±í…ŒìŠ¤íŒ… ì„¤ì •")

    window = st.sidebar.slider("ëª¨ë©˜í…€ ìœˆë„ìš° (ê°œì›”)", 3, 12, 6)
    top_n_stocks = st.sidebar.slider("ì„ íƒ ì¢…ëª© ìˆ˜", 5, min(25, len(tickers)), min(15, len(tickers)))
    upper_bound = st.sidebar.slider("ìµœëŒ€ ê°€ì¤‘ì¹˜ (%)", 5, 20, 20) / 100
    lower_bound = st.sidebar.slider("ìµœì†Œ ê°€ì¤‘ì¹˜ (%)", 1, 5, 1) / 100

    benchmark_display = st.sidebar.selectbox(
        "ë²¤ì¹˜ë§ˆí¬",
        list(BENCHMARK_OPTIONS.keys()),
        index=2
    )
    benchmark_ticker = BENCHMARK_OPTIONS[benchmark_display]

    # ì‹¤í–‰ ë²„íŠ¼
    if st.sidebar.button("ğŸš€ í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±", type="primary"):
        if len(tickers) < 5:
            st.error("ìµœì†Œ 5ê°œ ì´ìƒì˜ í‹°ì»¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        try:
            with st.container("ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì¤‘..."):
                # í–¥ìƒëœ ë°ì´í„° ë¡œë” ì‚¬ìš©
                monthly_df, substitution_log = load_universe_data_enhanced(
                    tickers, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), fill_gaps
                )

                if monthly_df is None:
                    st.error("ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    return

                # ëŒ€ì²´ ë¡œê·¸ í‘œì‹œ
                if substitution_log:
                    st.subheader("ğŸ”„ ë°ì´í„° ëŒ€ì²´ ë¡œê·¸")
                    substitute_df = pd.DataFrame([
                        {
                            'ì›ë³¸ ìì‚°': original,
                            'ëŒ€ì²´ ìì‚°': info['substitute'],
                            'ëŒ€ì²´ ì‹œì‘ì¼': info['substitute_start'].strftime('%Y-%m-%d') if info['substitute_start'] else 'N/A',
                            'ëŒ€ì²´ ë°©ì‹': 'ìœ ì‚¬ìì‚°' if info['method'] == 'similar_asset' else 'ê¸°íƒ€'
                        }
                        for original, info in substitution_log.items()
                    ])
                    st.dataframe(substitute_df, use_container_width=True, hide_index=True)

                # ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë¡œë“œ
                benchmark_data = load_benchmark_data(
                    benchmark_ticker, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')
                )

                if benchmark_data is None:
                    st.error("ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    return

                if isinstance(benchmark_data, pd.Series):
                    benchmark_df = benchmark_data
                elif isinstance(benchmark_data, pd.DataFrame):
                    benchmark_df = benchmark_data.iloc[:, 0]
                else:
                    st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° íƒ€ì…: {type(benchmark_data)}")
                    return

                # ê³µí†µ ê¸°ê°„ ì¡°ì •
                common_start = max(monthly_df.index[0], benchmark_df.index[0])
                common_end = min(monthly_df.index[-1], benchmark_df.index[-1])

                monthly_df = monthly_df.loc[common_start:common_end]
                benchmark_df = benchmark_df.loc[common_start:common_end]

                stock_returns = monthly_df.pct_change().dropna()
                benchmark_returns = benchmark_df.pct_change().dropna()

                # ë””ë²„ê¹… ì •ë³´
                st.write(f"ìì‚° ë°ì´í„° ê¸¸ì´: {len(stock_returns)}")
                st.write(f"ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ê¸¸ì´: {len(benchmark_returns)}")
                st.write(f"ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° íƒ€ì…: {type(benchmark_returns)}")

            with st.contatiner("ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ ì¤‘..."):
                # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
                portfolio_returns, weights_composition = run_backtest(
                    stock_returns, window, top_n_stocks, upper_bound, lower_bound
                )

                # í¬íŠ¸í´ë¦¬ì˜¤ì™€ ë²¤ì¹˜ë§ˆí¬ì˜ ê³µí†µ ì¸ë±ìŠ¤ ì°¾ê¸°
                common_index = portfolio_returns.index.intersection(benchmark_returns.index)

                # ê³µí†µ ì¸ë±ìŠ¤ë¡œ ì¬ì •ë ¬
                portfolio_returns_aligned = portfolio_returns.loc[common_index]
                benchmark_returns_aligned = benchmark_returns.loc[common_index]

                # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
                #st.write(f"í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ë°ì´í„° í¬ì¸íŠ¸: {len(portfolio_returns_aligned)}")
                #st.write(f"ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥  ë°ì´í„° í¬ì¸íŠ¸: {len(benchmark_returns_aligned)}")
                #st.write(f"ê³µí†µ ê¸°ê°„: {common_index[0].strftime('%Y-%m-%d')} ~ {common_index[-1].strftime('%Y-%m-%d')}")

                # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
                portfolio_metrics = calculate_performance_metrics(portfolio_returns_aligned)
                benchmark_metrics = calculate_performance_metrics(benchmark_returns_aligned)

            # ê²°ê³¼ í‘œì‹œ
            st.success(f"ë°±í…ŒìŠ¤íŒ… ë° í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„± ì™„ë£Œ! ({common_index[0].strftime('%Y-%m')} ~ {common_index[-1].strftime('%Y-%m')})")

            # ì„±ê³¼ ì§€í‘œ í…Œì´ë¸”
            col1, col2 = st.columns(2)

            with col1:
                st.subheader("ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼")
                benchmark_name = BENCHMARK_NAMES.get(benchmark_ticker, benchmark_ticker)

                # ì•ˆì „í•œ í¬ë§·íŒ… (ì´ì œ ëª¨ë“  ê°’ì´ floatì´ë¯€ë¡œ ì•ˆì „í•¨)
                metrics_df = pd.DataFrame({
                    'í¬íŠ¸í´ë¦¬ì˜¤': [
                        f"{portfolio_metrics['total_return']:.2%}",
                        f"{portfolio_metrics['annualized_return']:.2%}",
                        f"{portfolio_metrics['volatility']:.2%}",
                        f"{portfolio_metrics['sharpe_ratio']:.2f}",
                        f"{portfolio_metrics['max_drawdown']:.2%}"
                    ],
                    f'{benchmark_name}': [
                        f"{benchmark_metrics['total_return']:.2%}",
                        f"{benchmark_metrics['annualized_return']:.2%}",
                        f"{benchmark_metrics['volatility']:.2%}",
                        f"{benchmark_metrics['sharpe_ratio']:.2f}",
                        f"{benchmark_metrics['max_drawdown']:.2%}"
                    ]
                }, index=['ì´ ìˆ˜ìµë¥ ', 'ì—°í‰ê·  ìˆ˜ìµë¥ ', 'ì—°ë³€ë™ì„±', 'ìƒ¤í”„ ë¹„ìœ¨', 'ìµœëŒ€ ë‚™í­'])

                st.dataframe(metrics_df, use_container_width=True)

            with col2:
                st.subheader("ğŸ“‹ ë°±í…ŒìŠ¤íŒ… ì •ë³´")
                info_df = pd.DataFrame({
                    'í•­ëª©': ['ë¶„ì„ ê¸°ê°„', 'ì´ ì¢…ëª© ìˆ˜', 'ì„ íƒ ì¢…ëª© ìˆ˜', 'ë¦¬ë°¸ëŸ°ì‹±', 'ê°€ì¤‘ì¹˜ ë²”ìœ„'],
                    'ê°’': [
                        f"{common_index[0].strftime('%Y-%m')} ~ {common_index[-1].strftime('%Y-%m')}",
                        f"{len(tickers)}ê°œ",
                        f"{top_n_stocks}ê°œ",
                        "ë§¤ì›”",
                        f"{lower_bound:.1%} ~ {upper_bound:.1%}"
                    ]
                })
                st.dataframe(info_df, use_container_width=True, hide_index=True)

            # ìµœê·¼ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±ê³¼ ë¦¬ë°¸ëŸ°ì‹± ì •ë³´
            st.subheader(f"ğŸ“° í¬íŠ¸í´ë¦¬ì˜¤ ì—…ë°ì´íŠ¸ ({dt.date.today().strftime('%Y-%m')} ê¸°ì¤€)")

            if weights_composition:
                # ìµœê·¼ ë‘ ê°œ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
                recent_dates = sorted(weights_composition.keys())
                latest_date = recent_dates[-1]
                previous_date = recent_dates[-2] if len(recent_dates) > 1 else None

                current_weights = weights_composition[latest_date]
                previous_weights = weights_composition[previous_date] if previous_date else None

                col1, col2 = st.columns(2)

                with col1:
                    # í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±
                    st.write(f"**ğŸ“•{latest_date.strftime('%Y-%m-%d')} ë¦¬ë°¸ëŸ°ì‹± ì•ˆ**")

                    current_df = pd.DataFrame([
                        {'ì¢…ëª©': stock, 'ë¹„ì¤‘': f"{weight:.2%}"}
                        for stock, weight in sorted(current_weights.items(), key=lambda x: x[1], reverse=True)
                    ])
                    st.dataframe(current_df, use_container_width=True, hide_index=True)

                    # íŒŒì´ ì°¨íŠ¸
                    fig_pie = px.pie(
                        values=list(current_weights.values()),
                        names=list(current_weights.keys()),
                        title="ğŸ“’í˜„ì¬ ë¹„ì¤‘ ë¶„í¬"
                    )
                    fig_pie.update_layout(template="plotly_dark", height=400)
                    st.plotly_chart(fig_pie, use_container_width=True)

                with col2:
                    # ë¦¬ë°¸ëŸ°ì‹± ë³€í™”
                    if previous_weights:
                        st.write(f"**ğŸ“™ì „ì›” ëŒ€ë¹„ ë¦¬ë°¸ëŸ°ì‹± ë³€í™”** ({previous_date.strftime('%Y-%m-%d')} â†’ {latest_date.strftime('%Y-%m-%d')})")

                        changes = get_rebalancing_changes(current_weights, previous_weights)

                        if changes:
                            rebalancing_data = []
                            for stock, change_info in sorted(changes.items(), key=lambda x: abs(x[1]['change']), reverse=True):
                                action_emoji = "ğŸ“ˆ" if change_info['action'] == 'INCREASE' else "ğŸ“‰" if change_info['action'] == 'DECREASE' else "â¡ï¸"
                                rebalancing_data.append({
                                    'ì¢…ëª©': f"{action_emoji} {stock}",
                                    'ì´ì „ ë¹„ì¤‘': f"{change_info['previous']:.2%}",
                                    'í˜„ì¬ ë¹„ì¤‘': f"{change_info['current']:.2%}",
                                    'ë³€í™”': f"{change_info['change']:+.2%}"
                                })

                            rebalancing_df = pd.DataFrame(rebalancing_data)
                            st.dataframe(rebalancing_df, use_container_width=True, hide_index=True)

                            # ë¦¬ë°¸ëŸ°ì‹± ë³€í™” ì‹œê°í™”
                            stocks = list(changes.keys())
                            changes_values = [changes[stock]['change'] for stock in stocks]
                            colors = ['green' if x > 0 else 'red' for x in changes_values]

                            fig_rebal = go.Figure(data=[
                                go.Bar(x=stocks, y=[x*100 for x in changes_values],
                                      marker_color=colors,
                                      text=[f"{x:+.1%}" for x in changes_values],
                                      textposition='auto')
                            ])
                            fig_rebal.update_layout(
                                title="ğŸ“—ë¦¬ë°¸ëŸ°ì‹± ë³€í™” (%p)",
                                xaxis_title="ì¢…ëª©",
                                yaxis_title="ë¹„ì¤‘ ë³€í™” (%p)",
                                template="plotly_dark",
                                height=400
                            )
                            st.plotly_chart(fig_rebal, use_container_width=True)
                        else:
                            st.info("ì´ì „ ì›” ëŒ€ë¹„ ìœ ì˜ë¯¸í•œ ë¦¬ë°¸ëŸ°ì‹± ë³€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info("ë¹„êµí•  ì´ì „ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            # ì°¨íŠ¸ ìƒì„± - ìˆ˜ì •ëœ ë¶€ë¶„
            st.subheader("ğŸ“ˆ ì„±ê³¼ ë¶„ì„")
            benchmark_name = BENCHMARK_NAMES.get(benchmark_ticker, benchmark_ticker)

            # ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
            st.write("=== ì‹œê°í™” ë°ì´í„° ê²€ì¦ ===")
            st.write(f"í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ìƒ˜í”Œ: {portfolio_returns_aligned.head(3).values}")
            st.write(f"ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥  ìƒ˜í”Œ: {benchmark_returns_aligned.head(3).values}")
            st.write(f"í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  NaN ê°œìˆ˜: {portfolio_returns_aligned.isna().sum()}")
            st.write(f"ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥  NaN ê°œìˆ˜: {benchmark_returns_aligned.isna().sum()}")

            # ëˆ„ì  ìˆ˜ìµë¥ 
            cumulative_portfolio = (1 + portfolio_returns_aligned).cumprod() - 1
            cumulative_benchmark = (1 + benchmark_returns_aligned).cumprod() - 1

            fig1 = go.Figure()
            fig1.add_trace(go.Scatter(
                x=cumulative_portfolio.index,
                y=cumulative_portfolio * 100,
                mode='lines',
                name='í¬íŠ¸í´ë¦¬ì˜¤',
                line=dict(color='deeppink', width=2)
            ))
            fig1.add_trace(go.Scatter(
                x=cumulative_benchmark.index,
                y=cumulative_benchmark * 100,
                mode='lines',
                name=benchmark_name,
                line=dict(color='royalblue', width=2, dash='dash')
            ))
            fig1.update_layout(
                title="ëˆ„ì  ìˆ˜ìµë¥  ë¹„êµ",
                xaxis_title="ë‚ ì§œ",
                yaxis_title="ëˆ„ì  ìˆ˜ìµë¥  (%)",
                hovermode='x unified',
                template="plotly_dark"
            )
            st.plotly_chart(fig1, use_container_width=True)

            # 4ê°œ ì°¨íŠ¸ë¥¼ 2x2ë¡œ ë°°ì¹˜
            col1, col2 = st.columns(2)

            with col1:
                # ì›”ë³„ ìˆ˜ìµë¥  ë¶„í¬
                fig2 = go.Figure()
                fig2.add_trace(go.Histogram(
                    x=portfolio_returns_aligned * 100,
                    name='í¬íŠ¸í´ë¦¬ì˜¤',
                    opacity=0.7,
                    marker_color='deeppink',
                    nbinsx=20
                ))
                fig2.add_trace(go.Histogram(
                    x=benchmark_returns_aligned * 100,
                    name=benchmark_name,
                    opacity=0.7,
                    marker_color='royalblue',
                    nbinsx=20
                ))
                fig2.update_layout(
                    title="ì›”ë³„ ìˆ˜ìµë¥  ë¶„í¬",
                    xaxis_title="ì›”ë³„ ìˆ˜ìµë¥  (%)",
                    yaxis_title="ë¹ˆë„",
                    barmode='overlay',
                    template="plotly_dark"
                )
                st.plotly_chart(fig2, use_container_width=True)

            with col2:
                # ë¡¤ë§ ìƒ¤í”„ ë¹„ìœ¨ (12ê°œì›”)
                rolling_sharpe_portfolio = portfolio_returns_aligned.rolling(12).mean() / portfolio_returns_aligned.rolling(12).std() * np.sqrt(12)
                rolling_sharpe_benchmark = benchmark_returns_aligned.rolling(12).mean() / benchmark_returns_aligned.rolling(12).std() * np.sqrt(12)

                fig3 = go.Figure()
                fig3.add_trace(go.Scatter(
                    x=rolling_sharpe_portfolio.index,
                    y=rolling_sharpe_portfolio,
                    mode='lines',
                    name='í¬íŠ¸í´ë¦¬ì˜¤',
                    line=dict(color='deeppink', width=2)
                ))
                fig3.add_trace(go.Scatter(
                    x=rolling_sharpe_benchmark.index,
                    y=rolling_sharpe_benchmark,
                    mode='lines',
                    name=benchmark_name,
                    line=dict(color='royalblue', width=2, dash='dash')
                ))
                fig3.update_layout(
                    title="12ê°œì›” ë¡¤ë§ ìƒ¤í”„ ë¹„ìœ¨",
                    xaxis_title="ë‚ ì§œ",
                    yaxis_title="ìƒ¤í”„ ë¹„ìœ¨",
                    hovermode='x unified',
                    template="plotly_dark"
                )
                st.plotly_chart(fig3, use_container_width=True)

            # ë‚™í­ ë¹„êµ ì°¨íŠ¸
            portfolio_cumulative = (1 + portfolio_returns_aligned).cumprod()
            portfolio_running_max = portfolio_cumulative.expanding().max()
            portfolio_drawdown = (portfolio_cumulative - portfolio_running_max) / portfolio_running_max

            benchmark_cumulative = (1 + benchmark_returns_aligned).cumprod()
            benchmark_running_max = benchmark_cumulative.expanding().max()
            benchmark_drawdown = (benchmark_cumulative - benchmark_running_max) / benchmark_running_max

            fig4 = go.Figure()
            fig4.add_trace(go.Scatter(
                x=portfolio_drawdown.index,
                y=portfolio_drawdown * 100,
                fill='tonexty',
                mode='lines',
                name='í¬íŠ¸í´ë¦¬ì˜¤',
                line=dict(color='deeppink', width=1),
                fillcolor='rgba(255,20,147,0.3)'
            ))
            fig4.add_trace(go.Scatter(
                x=benchmark_drawdown.index,
                y=benchmark_drawdown * 100,
                fill='tonexty',
                mode='lines',
                name=benchmark_name,
                line=dict(color='royalblue', width=1),
                fillcolor='rgba(65,105,225,0.3)'
            ))
            fig4.update_layout(
                title="ë‚™í­ (Drawdown) ë¹„êµ",
                xaxis_title="ë‚ ì§œ",
                yaxis_title="ë‚™í­ (%)",
                hovermode='x unified',
                template="plotly_dark"
            )
            st.plotly_chart(fig4, use_container_width=True)

            # í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± íˆìŠ¤í† ë¦¬
            st.subheader("ğŸ“‘ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± íˆìŠ¤í† ë¦¬")

            if weights_composition:
                recent_dates = sorted(weights_composition.keys())[-5:]  # ìµœê·¼ 5ê°œì›”

                for date_key in recent_dates:
                    weights = weights_composition[date_key]

                    with st.expander(f"{date_key.strftime('%Y-%m-%d')} í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±"):
                        weights_df = pd.DataFrame([
                            {'ì¢…ëª©': stock, 'ê°€ì¤‘ì¹˜': f"{weight:.2%}"}
                            for stock, weight in sorted(weights.items(), key=lambda x: x[1], reverse=True)
                        ])

                        col1, col2 = st.columns([2, 1])
                        with col1:
                            st.dataframe(weights_df, use_container_width=True, hide_index=True)

                        with col2:
                            # íŒŒì´ ì°¨íŠ¸
                            fig_pie = px.pie(
                                values=list(weights.values()),
                                names=list(weights.keys()),
                                title="ê°€ì¤‘ì¹˜ ë¶„í¬"
                            )
                            fig_pie.update_layout(template="plotly_dark", height=300)
                            st.plotly_chart(fig_pie, use_container_width=True)

        except Exception as e:
            st.error(f"ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            import traceback
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

if __name__ == "__main__":
    main()
